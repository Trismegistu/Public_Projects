{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFXOPcAjzOM"
      },
      "source": [
        "# Mini-Project 3: Classification of Image Data \n",
        "\n",
        "**Authors**: Antoine Bonnet, Dragos Secrieru and Cyril Saidane \n",
        "\n",
        "**Course**: COMP 551: Applied Machine Learning, McGill University\n",
        "\n",
        "In this project, we implement a multilayer perceptron from scratch and use it to classify image data from the benchmark Fashion-MNIST dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4se3aS_jJXQ"
      },
      "source": [
        "## Task 1: Acquire, preprocess, and analyze the data\n",
        "\n",
        "In this section, we load and pre-process the Fashion-MNIST dataset for later use. \n",
        "\n",
        "### 1.0 Resource imports\n",
        "\n",
        "We first import several Python libraries. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MgwO4GgjL4j"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import sklearn\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8XVqr-omjPg"
      },
      "source": [
        "You may need to run the following command in your terminal to gain access to the Fashion-MNIST dataset from TensorFlow:\n",
        "\n",
        "`pip install tensorflow_datasets`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rEqH5EsjN5F"
      },
      "source": [
        "### 1.1 Loading and exploring the data\n",
        "\n",
        "We first load the [Fashion-MNIST](https://www.kaggle.com/zalando-research/fashionmnist) from TensorFlow, and split it into training and testing sets. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lSjeZ_Jk41k",
        "outputId": "187d7def-1c9a-481f-a58f-bd15e3f68b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(Xtrain, Ytrain), (Xtest, Ytest) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzVYv_Cso98U"
      },
      "source": [
        "This dataset contains a training set of 60K instances and a test set of 10K instances, where each instance corresponds ot a 28x28 grayscale image labelled by one of 10 classes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXvy9Hn2mTy8",
        "outputId": "e9c0dc81-1a91-46a2-f6ef-417e6a930ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features: (60000, 28, 28)\n",
            "Training labels: (60000,)\n",
            "Testing features: (10000, 28, 28)\n",
            "Testing labels: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Shape of dataset\n",
        "print(\"Training features:\", Xtrain.shape)\n",
        "print(\"Training labels:\", Ytrain.shape)\n",
        "print(\"Testing features:\", Xtest.shape)\n",
        "print(\"Testing labels:\", Ytest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pED0MXLj30_D"
      },
      "source": [
        "The labels belong to 10 different classes, encoded as follows: \n",
        "\n",
        "\n",
        "0.   T-shirt / top\n",
        "1.   Trouser\n",
        "2.   Pullover\n",
        "3.   Dress\n",
        "4.   Coat\n",
        "5.   Sandal\n",
        "6.   Shirt\n",
        "7.   Sneaker\n",
        "8.   Bag\n",
        "9.   Ankle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCZyg-WKjRTg"
      },
      "source": [
        "Each image is a $28 \\times 28$ matrix, where each matrix entry is a pixel intensity value between $0$ and $255$. For better intuition, we show a few examples of images from the training set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iecLE1fWjVLl",
        "outputId": "d96b3e3a-f51f-4060-ed29-11986e86b04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label:  9\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Label: \", Ytrain[0])\n",
        "plt.imshow(Xtrain[0], cmap=\"gray\") \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "MPNVZbWpoocV",
        "outputId": "180957d2-fd97-4684-ad61-6931126012dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label:  0\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Label: \", Ytrain[1])\n",
        "plt.imshow(Xtrain[1], cmap=\"gray\") \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0TYaRrvjVwb"
      },
      "source": [
        "### 1.2 Preprocessing data\n",
        "\n",
        "In this section, we prepare the downloaded data to be used by the multilayer perceptron. \n",
        "\n",
        "We first vectorize each $28 \\times 28$ image into a vector of dimension $784 \\times 1$. \n",
        "\n",
        "The dimensions of each data matrix is reshaped as: \n",
        "\n",
        "*   $X_{\\text{train}}$: $60000 \\times 28 \\times 28 \\to 60000 \\times 784$\n",
        "*   $X_{\\text{test}}$: $10000 \\times 28 \\times 28 \\to 10000 \\times 784$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sri4_WCnpXla"
      },
      "outputs": [],
      "source": [
        "# Reshape dataset to have a single channel\n",
        "trainX = Xtrain.reshape((Xtrain.shape[0], Xtrain.shape[1] * Xtrain.shape[2]))\n",
        "testX = Xtest.reshape((Xtest.shape[0], Xtest.shape[1] * Xtest.shape[2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOA00rtN0vxR",
        "outputId": "21513129-6672-4881-bc65-2e9f8defa80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qlvbRbapX9_"
      },
      "source": [
        "We also normalize the intensity values of each image so that each image matrix entry has standard normal distribution over the whole training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iyJ4w_o0J4d"
      },
      "outputs": [],
      "source": [
        "# Calculate training set average and standard deviation\n",
        "trainXAvg = trainX.mean(axis=0)\n",
        "trainXsd = trainX.std(axis=0)\n",
        "\n",
        "# Normalize by setting mean 0 and std 1\n",
        "trainData = (trainX - trainXAvg)/trainXsd\n",
        "testData = (testX - trainXAvg)/trainXsd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N5AKkZV0VWK"
      },
      "source": [
        "We convert the labels to one-hot encoding, i.e. every label $y \\in \\{1, 2, \\ldots, 10\\}$ is converted to vector of size 10, with a single unit value at the index of the class associated with label $y$. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RktmRXknqvXw"
      },
      "outputs": [],
      "source": [
        "trainLabels = np.zeros((Ytrain.size, 10))\n",
        "trainLabels[np.arange(Ytrain.size),Ytrain] = 1\n",
        "\n",
        "testLabels = np.zeros((Ytest.size, 10))\n",
        "testLabels[np.arange(Ytest.size),Ytest] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0L8LuHAuMqX"
      },
      "source": [
        "### 1.3 Dataset Class\n",
        "\n",
        "To make our life more enjoyable, we define a Dataset class which divides each dataset into its training and testing sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNUCe7NKuMLk"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self,trainData,trainLabels,testData,testLabels):\n",
        "      self.trainData = trainData\n",
        "      self.trainLabels = trainLabels\n",
        "      self.testData = testData\n",
        "      self.testLabels = testLabels\n",
        "      return\n",
        "\n",
        "# Instantiate fashionMNIST class\n",
        "fashionMNIST = Dataset(trainData,trainLabels,testData,testLabels)\n",
        "\n",
        "# Instantiate unnormalized fashionMNIST class\n",
        "unnormFashionMNIST = Dataset(trainX, trainLabels, testX, testLabels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aayP_XOjYNE"
      },
      "source": [
        "## Task 2: Implement a Multilayer Perceptron\n",
        "\n",
        "In this section, we implement a Multilayer Perceptron (MLP) from scratch to classify image data. Our implementation will include backpropagation and mini-batch gradient descent algorithm (SGD). \n",
        "\n",
        "**Model construction**\n",
        "\n",
        "Our MLP will consist of 3 types of layers: \n",
        "\n",
        "1.   **Input layer**: Vector $x$ of length $D = 784$ representing a vectorized image. \n",
        "2.   **Hidden layers**: We have $K$ hidden layers, where each $k$-th hidden layer corresponds to a vector $z^{(k)}$ of length $M_k$. \n",
        "3.   **Output layer**: Vector $\\hat{y}$ of length $C=10$, where each entry $\\hat{y}_c$ is the estimated probability that the instance $x$ belongs to class $c$. \n",
        "\n",
        "**Weights, biases and activation functions**\n",
        "\n",
        "The weights between every pair of adjacent hidden layers $z^{(k-1)} \\in \\mathbb{R}^{M_{k-1}}$ and $z^{(k)}\\in \\mathbb{R}^{M_{k}}$ (including the input layer $x \\equiv z^{(0)}$ and the output layer $\\hat{y} \\equiv z^{(K+1)}$) are given by the matrix $W^{(k)} \\in \\mathbb{R}^{M_{k} \\times M_{k-1}}$, where each entry $W_{i,j}^{(k)}$ is the weight of the connection from node $z_{j}^{(k)}$ to node $z_{i}^{(k+1)}$. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeTxh0qbje7E"
      },
      "source": [
        "### 2.1 Activation functions\n",
        "\n",
        "Every layer in the network is computed from a chosen activation function. We will explore various activation functions for the hidden layers; the `logistic`, `softmax`, `ReLu`, `leakyReLu` and `tanh` activation functions. \n",
        "\n",
        "\n",
        "\n",
        "*   `logistic`: $h(x) = \\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
        "*   `softmax`: $h(x)_c = \\frac{e^{x_c}}{\\sum_{c'} e^{x_c'}}$\n",
        "*    `ReLu`: $h(x) = max(x, 0)$\n",
        "*   `leakyReLu`: $h(x, \\gamma) = max(x, 0) + \\gamma \\cdot min(x,0)$\n",
        "*   `tanh`: $h(x) = 2 \\sigma(x) - 1$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfMXj3PTyodv"
      },
      "outputs": [],
      "source": [
        "logistic = lambda z: np.reciprocal(1 + np.exp(-z))\n",
        "softmax = lambda z: np.exp(z)/np.sum(np.exp(z))\n",
        "ReLu = lambda z: np.maximum(z,0)\n",
        "leakyReLu = lambda z, gamma: np.maximum(z,0) + gamma*np.minimum(z,0)\n",
        "tanh = lambda z: 2*logistic(z) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK68_7sBRQgt"
      },
      "source": [
        "We also add the corresponding derivatives of each activation function. \n",
        "*   `logisticD`: $h'(x) = \\sigma(x) \\cdot (1-\\sigma(x))$\n",
        "*   `softmaxD`: $h(x)_c = \\text{softmax}(x) \\cdot (1-\\text{softmax}(c))$\n",
        "*   `ReLuD`: $h'(x) = \\begin{cases} 1 & x \\geq 0 \\\\ 0 & x < 0\\end{cases}$\n",
        "*   `leakyReLuD`: $h'(x, \\gamma) = \\begin{cases} 1 & x \\geq 0 \\\\ \\gamma & x < 0\\end{cases}$\n",
        "*   `tanhD`: $h(x) = 1 - \\tanh(x)^2$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAlIHixGRHog"
      },
      "outputs": [],
      "source": [
        "logisticD = lambda z: np.multiply(logistic(z), (1-logistic(z)))\n",
        "softmaxD = lambda z: np.multiply(softmax(z), (1-softmax(z)))\n",
        "ReLuD = lambda z: (z>0).astype(int)\n",
        "leakyReLuD = lambda z, gamma: (z>0).astype(int) + gamma*(z<0).astype(int)\n",
        "tanhD = lambda z: 1 - np.square(tanh(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNZ0WZuWHzTh"
      },
      "source": [
        "We also define an activation function class, comprising both the actual activation function and its derivative, for later ease of use. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjEsJ69CGpvu"
      },
      "outputs": [],
      "source": [
        "class activation: \n",
        "  def __init__(self,function,derivative, params=None):\n",
        "    if (params == None):\n",
        "      self.function = function\n",
        "      self.derivative = derivative\n",
        "    else: # For leaky ReLu we might have gammas\n",
        "      self.function = lambda z: function(z, params)\n",
        "      self.derivative = lambda z: derivative(z, params)\n",
        "\n",
        "logisticAc = activation(logistic, logisticD)\n",
        "softmaxAc= activation(softmax, softmaxD)\n",
        "ReLuAc = activation(ReLu, ReLuD)\n",
        "tanhAc = activation(tanh, tanhD)\n",
        "leakyReLuAc = activation(leakyReLu, leakyReLuD, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYHuHcoIvuSO"
      },
      "source": [
        "### 2.2 Forward Propagation\n",
        "\n",
        "Let's say every hidden layer $k$ has an activation function denoted by $h^{(k)}$. Given an input layer $z^{(k-1)}$, we can obtain the next layer's value $z^{(k)}$ by recursively applying the feed-forward rule for every layer $k$:\n",
        "\n",
        "$$z^{(k)} = h^{(k)} (u^{(k)}) = h^{(k)} \\big( W^{(k)} \\cdot z^{(k-1)} + b^{(k)}\\big)$$\n",
        "\n",
        "Given an input $x^{(n)}$, we can obtain the network's prediction $\\hat{y}^{(n)}$ by propagating forward over every layer $k$ until we reach the output layer. As we are concerned with image classification, the output layer $\\hat{y}$ is obtained from the last hidden layer $z^{(K)}$ using the softmax activation function: \n",
        "$$ \\hat{y} = \\text{softmax}(u^{(K+1)}) = \\text{softmax}(W^{(K+1)} z^{(K)} + b^{(K+1)}) $$\n",
        "$$ \\hat{y}_c = \\frac{e^{z^{(K)}_c}}{\\sum_{c'=1}^{C} e^{z^{(K)}_{c'}}} \\; \\forall 1 \\leq c \\leq C.$$\n",
        "\n",
        "$$\\frac{\\partial}{\\partial u_c} \\hat{y}_k = \\begin{cases} \\hat{y}_k (1-\\hat{y}_k) & k = c \\\\ - \\hat{y}_c \\hat{y}_k & k \\neq c\\end{cases} $$\n",
        "\n",
        "In particular, the predicted class of the input $x$ corresponds to\n",
        "$$ \\hat{c} = \\text{argmax}_c \\; \\hat{y}_c.$$\n",
        "\n",
        "We use the above feed-forward rule to propagate the layer values from input $x$ to output $\\hat{y}$ in the network.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "docAlqN8rnDe"
      },
      "outputs": [],
      "source": [
        "# FEED-FORWARD: Compute layer values\n",
        "def feed_forward(x, activations, weights, biases, depth):\n",
        "  Z = []  # List of layer values (with activation)\n",
        "  U = []  # List of layer values (without activation)\n",
        "  Zk = x\n",
        "  for k in range(depth+1):  # Compute all hidden layers Z{1}, ..., Z{K+1}, yh\n",
        "    act = activations[k]   # h{k}\n",
        "    Wk = weights[k]        # W{k}\n",
        "    Bk = biases[k]         # b{k} \n",
        "    Uk = np.dot(Wk, Zk) + Bk # u{k} = W{k} * z{k-1} + b{k}\n",
        "    Zk = act.function(Uk) # z{k} = h{k}(u{k})\n",
        "    Z.append(Zk)\n",
        "    U.append(Uk)\n",
        "  return U, Z\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRfqY0Tirnlf"
      },
      "source": [
        "### 2.3 Backpropagation\n",
        "\n",
        "At the output layer is computed the cost function, which is the average loss of the sample\n",
        "\n",
        "$$J(y, \\hat{y}) = \\frac{1}{n} \\sum_n L(y^{(n)}, \\hat{y}^{(n)}) $$\n",
        "\n",
        "We want to update the weight parameters $W^{(1)}, \\ldots, W^{(K+1)} $ and bias parameters $B^{(1)}, \\ldots, B^{(K+1)} $ using gradient descent by computing the partial derivatives \n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial W^{(1)}}, \\ldots, \\frac{\\partial J}{\\partial W^{(K+1)}} \\quad \\text{and} \\quad \\frac{\\partial J}{\\partial B^{(1)}}, \\ldots, \\frac{\\partial J}{\\partial B^{(K+1)}}$$\n",
        "\n",
        "For any $1 \\leq k \\leq K+1$,\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial W^{(k)}} = \\frac{1}{n} \\sum_n \\frac{\\partial }{\\partial W^{(K)}} L(y^{(n)},\\hat{y}^{(n)}) $$\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial B^{(k)}} = \\frac{1}{n} \\sum_n \\frac{\\partial }{\\partial B^{(K)}} L(y^{(n)},\\hat{y}^{(n)}) $$\n",
        "\n",
        "The loss function used for multi-class classification is the softmax-cross-entropy cost function\n",
        "\n",
        "$$L(y, \\hat{y}) = \\sum_c y_c \\log \\hat{y}_c$$\n",
        "\n",
        "Using backpropagation, we can start from the output layer $\\hat{y} = z^{(K+1)}$ by initializing \n",
        "\n",
        "$$\\frac{\\partial L}{\\partial z^{(K+1)}} = \\hat{y} - y$$\n",
        "\n",
        "as given above and then computing the partial derivatives by solving the following rules recursively ($\\odot$ denotes coordinate-wise product): \n",
        "\n",
        "$$\\underbrace{\\frac{\\partial L}{\\partial u^{(k)}}}_{M_k \\times 1}  = \\underbrace{\\frac{\\partial L}{\\partial z^{(k)}}}_{M_k \\times 1}  \\odot \\underbrace{\\frac{\\partial h^{(k)}}{\\partial u^{(k)}}}_{M_k \\times 1} $$\n",
        "\n",
        "$$\\underbrace{\\frac{\\partial L}{\\partial W^{(k)}}}_{M_k \\times M_{k-1}} = \\underbrace{\\frac{\\partial L}{\\partial u^{(k)}}}_{M_k \\times 1} \\cdot \\underbrace{\\big(z^{(k-1)}\\big)^T}_{1 \\times M_{k-1}}   $$\n",
        "\n",
        "$$\\underbrace{\\frac{\\partial L}{\\partial b^{(k)}}}_{M_k \\times 1}  = \\underbrace{\\frac{\\partial L}{\\partial u^{(k)}}}_{M_k \\times 1} $$\n",
        "\n",
        "$$\\underbrace{\\frac{\\partial L}{\\partial z^{(k-1)}}}_{M_{k-1} \\times 1}   = \\underbrace{\\big(W^{(k)}\\big)^T}_{M_{k-1} \\times M_k}  \\cdot \\underbrace{\\frac{\\partial L}{\\partial u^{(k)}}}_{M_k \\times 1}   $$\n",
        "\n",
        "We use the above rules to back-propagate the gradients through the MLP.\n",
        "\n",
        "Sources: \n",
        "https://web.stanford.edu/class/cs224n/readings/gradient-notes.pdf\n",
        "https://sudeepraja.github.io/Neural/\n",
        "\n",
        "https://machinelearningmastery.com/application-of-differentiations-in-neural-networks/?fbclid=IwAR0kPYmYmtayPpz4uK185JezFmUYWrAm9qC1vd8kEEFQA6aKUkqEGoaOFHQ\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHOxCcYZmOEz"
      },
      "outputs": [],
      "source": [
        "# BACKPROPAGATION: Compute gradients recursively from right to left\n",
        "def back_prop(x, y, U, Z, activations, weights, biases, depth):\n",
        "  dW = [None] * (depth+1) # List of partial derivatives dL/dWk\n",
        "  dB = [None] * (depth+1) # List of partial derivatives dL/dBk\n",
        "  dZ = [None] * (depth+1) # List of partial derivatives dL/dZk\n",
        "  dZ[-1] = Z[-1] - y # last layer: dL/dyhat = yhat - y, yhat=Z[-1]   (C x 1)\n",
        "\n",
        "  # For each layer, recursively compute gradients \n",
        "  for k in range(depth, 0, -1): # for k = K, K-1, ..., 1\n",
        "    act = activations[k]\n",
        "    Wk = weights[k] # W{k}\n",
        "    if (k == depth): \n",
        "      dUk = dZ[k]\n",
        "    else: \n",
        "      dUk = np.multiply(dZ[k], act.derivative(U[k])) # dL/dU{k} = dL/dZ{k} * h{k}'(U{k}) coordinatewise    [M{k} x 1]\n",
        "    dW[k] = np.outer(dUk, Z[k-1])  # dL/dW{k} = dL/dU{k} * Z{k-1}.T   [M{k} x 1] x [1 x M{k-1}] = [M{k} x M{k-1}]\n",
        "    dB[k] = dUk # dL/dB{k} = dL/dU{k}   [M{k} x 1]\n",
        "    dZ[k-1] = np.dot(Wk.T, dUk) # dL/dZ{k-1} = (W{k}).t*dL/dU{k}   [M{k-1} x M{k}] x [M{k} x 1] = [M{k-1} x 1]\n",
        "\n",
        "  # Compute first layer separately \n",
        "  dU1 = np.multiply(dZ[0], activations[0].derivative(U[0]))\n",
        "  dW[0] = np.outer(dU1,x) \n",
        "  dB[0] = dU1\n",
        "  return dW, dB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPREbM_5pthW"
      },
      "source": [
        "### 2.4 Multilayer Perceptron Model\n",
        "\n",
        "We implement the MLP as a Python class. The class constructor `__init__` takes as input the following parameters: \n",
        "\n",
        "\n",
        "*   `activation`: activation function class for all hidden layers (e.g. ReLu)\n",
        "*   `depth`: number $K$ of hidden layers (e.g. 2) \n",
        "*   `widths`: vector of length $K$ representing the number of units in each hidden layer (e.g. $[64,64]$). \n",
        "\n",
        "The class constructor then initializes the weights and biases and other properties of the MLP. \n",
        "\n",
        "The `MLP` class consists of the following functions: \n",
        "*   `fit`: From the training data (input vector $x$ and labels $y$), as well as other hyperparameters (e.g. the learning rate, the maximum number of gradient descent iterations and the threshold for convergence), this function first initializes the weights and biases of the model. It then trains the model by modifying the model parameters through gradient descent. \n",
        "*   `predict`: From a set of input points given as an image matrix $X$, this function outputs predicted labels $\\hat{y}$.\n",
        "*   `evaluate_acc`: From the true labels $y$, this function computes the accuracy of the model's predicted labels $\\hat{y}$. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs28Lu5yjiRk"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import DisplayHandle\n",
        "\n",
        "class MLP:\n",
        "\n",
        "  # Model initialization with hyperparameters\n",
        "  def __init__(self, activations = [ReLuAc, ReLuAc], depth = 2, widths = [64, 64], dropout_rate = 0):\n",
        "    self.activations = activations\n",
        "    self.activations.append(softmaxAc) # List of activation functions for each layer\n",
        "    self.depth = depth    # K = Number of hidden layers\n",
        "    self.widths = widths  # [M{1}, ..., M{k}] = Number of units per hidden layer\n",
        "    self.weights = []     # List of weight matrices W{1}, ..., W{K+1}\n",
        "    self.biases = []      # List of bias vectors B{1}, ..., B{K+1}\n",
        "    self.dropout_rate = dropout_rate \n",
        "    self.C = 0 # Number of classes\n",
        "\n",
        "  # Model training using training data        \n",
        "  def fit(self, X, Y, optimizer):\n",
        "    N, D = X.shape # D = number of features, N = number of input instances\n",
        "    self.C = Y.shape[1] # C = number of classes\n",
        "\n",
        "    # Initialize weights: Normal(0,0.0001) distribution\n",
        "    # Initialize Biases: Exponential(0.01) distribution (positive for ReLu initialization)\n",
        "    all_widths = self.widths # [D, width1, ..., widthK, C]\n",
        "    all_widths.insert(0,D)\n",
        "    all_widths.append(self.C) \n",
        "    for k in range(self.depth+1): # W{1}, W{2},...,W{K+!}\n",
        "      Wk = np.random.randn(all_widths[k+1],all_widths[k]).astype(float) * .01 \n",
        "      Bk = np.random.exponential(scale=0.01,size=all_widths[k+1]).astype(float)\n",
        "      self.weights.append(Wk)\n",
        "      self.biases.append(Bk)\n",
        "\n",
        "    # If we add dropout regularization, set some weights to 0. \n",
        "    if (self.dropout_rate > 0): \n",
        "      for k in range(self.depth+1): \n",
        "        Wk = self.weights[k]\n",
        "        numEntries = Wk.shape[0]*Wk.shape[1]\n",
        "        numDropout = round(numEntries * self.dropout_rate)\n",
        "        indices = np.random.choice(numEntries,replace=False,size=numDropout)\n",
        "        Wk[np.unravel_index(indices, Wk.shape)] = 0 \n",
        "        self.weights[k] = Wk\n",
        "\n",
        "    # Helper function to compute the gradient dJ/dW{k}, dJ/dB{k} for all k\n",
        "    def gradient(X, Y, activations, weights, biases):\n",
        "      weightGrad = [np.zeros_like(Wk) for Wk in weights] # List of gradients [dLdW{1}, ..., dLdW{K+1}]\n",
        "      biasGrad = [np.zeros_like(Bk) for Bk in biases] # List of gradients [dLdB{1}, ..., dLdB{K+1}]\n",
        "      # For each row in the input, compute gradients dL/dWk and dL/dBk\n",
        "      for n in range(X.shape[0]):\n",
        "        x = X[n]; y = Y[n]\n",
        "        U, Z = feed_forward(x, activations, weights, biases, self.depth)\n",
        "        dW, dB = back_prop(x, y, U, Z, activations, weights, biases, self.depth)\n",
        "        for k in range(len(dW)):\n",
        "          weightGrad[k] += dW[k]\n",
        "          biasGrad[k] += dB[k]\n",
        "      # Average out gradients over all single inputs (x, y) \n",
        "      weightGrad = [dW / X.shape[0] for dW in weightGrad]\n",
        "      biasGrad = [dB / X.shape[0] for dB in biasGrad]\n",
        "      return weightGrad, biasGrad\n",
        "\n",
        "    # Update weights using optimizer with initial weights and training data (x,y) \n",
        "    self.weights, self.biases, trainAccs, testAccs = optimizer.run(\n",
        "        gradient, X, Y, self.activations, self.weights, self.biases, self.depth)\n",
        "    return trainAccs, testAccs\n",
        "\n",
        "  # Predict new data using trained model\n",
        "  def predict(self, X):\n",
        "    ypred = np.zeros((X.shape[0], self.C)) # Initialize matrix of predictions\n",
        "    # For each subsequent input x, run model and get prediction\n",
        "    for n in range(X.shape[0]):\n",
        "        x = X[n]  \n",
        "        _, Z = feed_forward(x, self.activations, self.weights, self.biases, self.depth)\n",
        "        ypred[n] = Z[-1]\n",
        "    return ypred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye2VYtiT3JDx"
      },
      "source": [
        "We also implement a function that takes as input both the true labels and the predicted labels, and outputs the accuracy of the predictions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my099ujL3HhE"
      },
      "outputs": [],
      "source": [
        "# Evaluate the accuracy of predicted labels\n",
        "def evaluate_acc(y_true, y_pred):\n",
        "  pred_labels = np.zeros_like(y_pred)\n",
        "  pred_labels[np.arange(len(y_pred)), y_pred.argmax(1)] = 1 # One-hot encoding\n",
        "  numCorrect= np.sum(np.all(np.equal(y_true.astype(float), pred_labels), axis=1))\n",
        "  numTotal = pred_labels.shape[0]\n",
        "  return numCorrect/numTotal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI-zRwtU9g0G"
      },
      "source": [
        "### 2.5 Mini-batch splitting\n",
        " \n",
        "To train our model, we will use stochastic gradient descent with mini-batches. The function below randomly splits the data into mini-batches of desired size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RyKfvepItE3"
      },
      "outputs": [],
      "source": [
        "# Creates an array of mini-batches\n",
        "def mini_batches(X, Y, batch_size):\n",
        "    batches = []\n",
        "    N = X.shape[0] // batch_size\n",
        "    rem = X.shape[0] % batch_size\n",
        "    shuffle = np.random.permutation(X.shape[0])\n",
        "    Xtrain, Ytrain = X[shuffle], Y[shuffle]\n",
        "    for i in range(N):\n",
        "      X_mini = Xtrain[i*batch_size:(i + 1)*batch_size]\n",
        "      Y_mini = Ytrain[i*batch_size:(i + 1)*batch_size]\n",
        "      batches.append((X_mini, Y_mini))\n",
        "    if rem > 0: \n",
        "      X_mini = Xtrain[N*batch_size:]\n",
        "      Y_mini = Ytrain[N*batch_size:]\n",
        "      batches.append((X_mini, Y_mini))\n",
        "    return batches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW3eNeJeuMWo"
      },
      "source": [
        "### 2.6 Stochastic Gradient Descent\n",
        "For each mini-batch $B$ , we define the cost  \n",
        "\n",
        "$$J_B = \\frac{1}{|B|}  \\sum_{n \\in B} L(y^{(n)}, \\hat{y}^{(n)}).$$\n",
        "\n",
        "Using stochastic gradient descent with learning rate $\\alpha$, we update the weight and bias matrices of every $k$-th layer as follows: \n",
        "$$ W^{(k)} \\leftarrow W^{(k)} - \\alpha \\cdot \\frac{\\partial J_B}{\\partial W^{(k)}}$$\n",
        "$$ B^{(k)} \\leftarrow B^{(k)} - \\alpha \\cdot \\frac{\\partial J_B}{\\partial B^{(k)}}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ybptVbY6avU"
      },
      "outputs": [],
      "source": [
        "class GradientDescent:\n",
        "  def __init__(self, learning_rate=.001, max_iters=1e5, epsilon=1e-5, batchSize=32):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_iters = max_iters\n",
        "    self.epsilon = epsilon\n",
        "    self.batchSize = batchSize\n",
        "        \n",
        "  def run(self, gradient_fn, x, y, activations, weights, biases, depth):\n",
        "    # Train/test accuracies for each epoch\n",
        "    trainAccs = []\n",
        "    testAccs = []\n",
        "\n",
        "    # Separate data into mini batches\n",
        "    batches = mini_batches(x,y,self.batchSize)\n",
        "    norms = np.array([np.inf])\n",
        "    t = 0\n",
        "    batchIdx = 0\n",
        "\n",
        "    # While gradient norms are non-null, and iterations left\n",
        "    while np.any(norms > self.epsilon) and t < self.max_iters:\n",
        "\n",
        "      # If we have used all batches, make new random batches\n",
        "      if (batchIdx >= len(batches)): \n",
        "        batches = mini_batches(x,y,self.batchSize)\n",
        "        batchIdx = 0\n",
        "\n",
        "      # Find weight/bias gradient on the batch\n",
        "      (X_batch, Y_batch) = batches[batchIdx]\n",
        "      weightGrad, biasGrad = gradient_fn(X_batch, Y_batch, activations, weights, biases)\n",
        "\n",
        "      # Apply gradient descent on weights and biases\n",
        "      for k in range(len(weights)):\n",
        "        weights[k] -= self.learning_rate * weightGrad[k] \n",
        "        biases[k] -= self.learning_rate * biasGrad[k] \n",
        "      t += 1\n",
        "      batchIdx += 1\n",
        "      norms = np.array([np.linalg.norm(g) for g in (weightGrad+biasGrad)])\n",
        "\n",
        "    return weights, biases, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgVp2JV9zS3A"
      },
      "source": [
        "### 2.7 Hyperparameter tuning\n",
        "\n",
        "We will use the SciKit Learn grid search provided functions to perform hyperparameter tuning. \n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfQyctxmoUFY"
      },
      "outputs": [],
      "source": [
        "# Splitting function: Creates list of indices for K cross-validation splits\n",
        "def cross_validation_split(dataset, K):\n",
        "  # Create list of indices for cross validation\n",
        "  N = dataset.trainData.shape[0] # Number of datapoints\n",
        "  size = math.floor(N/K)  # Size of each portion\n",
        "  idx = np.arange(N)      # Indices {0,1,...,N-1}\n",
        "  idx = np.random.permutation(idx)  # Shuffled indices \n",
        "  validationIDX = [list(idx[i:i+size]) for i in range(0,size*K,size)]\n",
        "  trainingIDX = [list(np.delete(idx,np.array(range(i,i+size)))) for i in range(0,size*K,size)]\n",
        "  return trainingIDX, validationIDX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsNcHqkdoNsr"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# K-fold Cross validation: iterates through each train/validation set \n",
        "# and returns the average result of each fold.\n",
        "paramMLP = ['activations', 'depth', 'widths', 'dropout_rate']\n",
        "paramGD = ['learning_rate', 'max_iters', 'epsilon', 'batchSize']\n",
        "\n",
        "def kfoldCV(dataset,K,hyperparameter):\n",
        "  # For each cross-validation split, train model, predict labels, report accuracy\n",
        "  trainingIDX, validationIDX = cross_validation_split(dataset, K)\n",
        "  validAccuracies = []\n",
        "  trainAccuracies = []\n",
        "  k = 1\n",
        "  for trainIDX, validIDX in zip(trainingIDX,validationIDX):\n",
        "    # Split dataset using training/validation indices\n",
        "    x_train = dataset.trainData[trainIDX]\n",
        "    y_train = dataset.trainLabels[trainIDX]\n",
        "    x_validation = dataset.trainData[validIDX]\n",
        "    y_validation = dataset.trainLabels[validIDX]\n",
        "\n",
        "    # Train arbitrary model using training set\n",
        "    hyp = deepcopy(hyperparameter)\n",
        "    hypMLP = {h:hyp[h] for h in hyp if h in paramMLP}\n",
        "    hypGD = {h:hyp[h] for h in hyp if h in paramGD}\n",
        "    mlp = MLP(**hypMLP) \n",
        "    optimizer = GradientDescent(**hypGD)   \n",
        "    mlp.fit(x_train, y_train, optimizer)   \n",
        "\n",
        "    # Predict labels using validation set, record validation accuracy\n",
        "    valid_pred = mlp.predict(x_validation)\n",
        "    validAcc = evaluate_acc(y_validation,valid_pred)\n",
        "    validAccuracies.append(validAcc)\n",
        "\n",
        "    # Predict labels using training set, record training accuracy\n",
        "    train_pred = mlp.predict(x_train)\n",
        "    trainAcc = evaluate_acc(y_train,train_pred)\n",
        "    trainAccuracies.append(trainAcc)\n",
        "\n",
        "  return validAccuracies, trainAccuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SWfkpWSoNIg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Hyperparameter tuning function: Chooses hyperparameters with highest average\n",
        "# validation accuracy and returns the test accuracy of the optimal model\n",
        "# hyperparameters = list of dictionaries of hyperparameters\n",
        "\n",
        "def hyperparameterTuning(dataset,K,hyperparameters):\n",
        "  # For each hyperparameter, perform k-fold cross validation\n",
        "  P = len(hyperparameters)\n",
        "  validAccuracies = np.zeros((P,K))\n",
        "  trainAccuracies = np.zeros((P,K))\n",
        "  models = []\n",
        "  for p in range(P):\n",
        "    hyperparameter = hyperparameters[p]\n",
        "    print(\"Hyperparameter tuning: Round\", p, \"\\n\\tHyperparameter:\", str(hyperparameter))\n",
        "    validAccuracies[p], trainAccuracies[p] = kfoldCV(dataset,K,hyperparameter)\n",
        "    print('\\tTrain Accuracies: ', trainAccuracies[p], \n",
        "          '\\n\\tValid Accuracies: ', validAccuracies[p])\n",
        "\n",
        "  # Find model with highest average validation accuracy\n",
        "  avgValAccs = np.mean(validAccuracies,1) \n",
        "  avgTrainAccs = np.mean(trainAccuracies,1)\n",
        "  bestValAcc = np.argmax(avgValAccs) \n",
        "  optParameter = deepcopy(hyperparameters[bestValAcc])\n",
        "  optValidAcc = avgValAccs[bestValAcc]\n",
        "  optTrainAcc = avgTrainAccs[bestValAcc]\n",
        "  return avgValAccs, avgTrainAccs, optParameter, optValidAcc, optTrainAcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6CQXKzGjtM-"
      },
      "source": [
        "## Task 3: Run experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVzjuGIpjt1O"
      },
      "source": [
        "###3.1: MLPs with ReLu activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZPM4m21W7RG"
      },
      "source": [
        "We first create an MLP with no hidden layers, which maps inputs to output with a softmax activation function directly. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7eh_3zMwvgO",
        "outputId": "37f5df20-fc8d-40d4-e24e-30ab47fcb8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.767625   0.76729167 0.77054167 0.77202083 0.768625  ] \n",
            "\tValid Accuracies:  [0.76933333 0.77166667 0.7635     0.76983333 0.76708333]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.802125   0.80047917 0.8003125  0.80277083 0.8006875 ] \n",
            "\tValid Accuracies:  [0.7975     0.79766667 0.79541667 0.803      0.79908333]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8151875  0.814875   0.81672917 0.81745833 0.81702083] \n",
            "\tValid Accuracies:  [0.81508333 0.82108333 0.81033333 0.80866667 0.81466667]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.843125   0.844375   0.84258333 0.84322917 0.84239583] \n",
            "\tValid Accuracies:  [0.84175    0.83375    0.8395     0.838      0.84283333]\n",
            "Hyperparameter tuning: Round 4 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.85310417 0.85445833 0.85452083 0.85222917 0.85522917] \n",
            "\tValid Accuracies:  [0.85       0.84975    0.84258333 0.85233333 0.84516667]\n",
            "Hyperparameter tuning: Round 5 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8585     0.85933333 0.85847917 0.85839583 0.85941667] \n",
            "\tValid Accuracies:  [0.85166667 0.85175    0.84966667 0.85241667 0.84791667]\n",
            "Hyperparameter tuning: Round 6 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.86472917 0.86435417 0.86310417 0.866      0.8679375 ] \n",
            "\tValid Accuracies:  [0.85108333 0.85216667 0.85208333 0.8515     0.85358333]\n",
            "Hyperparameter tuning: Round 7 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.87277083 0.86958333 0.86927083 0.872625   0.87208333] \n",
            "\tValid Accuracies:  [0.85466667 0.85233333 0.85741667 0.84966667 0.85525   ]\n",
            "Hyperparameter tuning: Round 8 \n",
            "\tHyperparameter: {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.87441667 0.87452083 0.8741875  0.87620833 0.87489583] \n",
            "\tValid Accuracies:  [0.8545     0.84891667 0.85716667 0.85291667 0.85191667]\n",
            "Optimal hyperparameters:  {'activations': [], 'depth': 0, 'widths': [], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8538666666666668\n",
            "Average training accuracy with optimal hyperparameters:  0.8712666666666667\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters: list of different parameter combinations\n",
        "learning_rates = [.001, .01, .1]\n",
        "max_iters = [5000, 10000, 15000]\n",
        "hyperparameters0 = [dict(activations = [], depth = 0, widths = [], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = m, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for L in learning_rates for m in max_iters]\n",
        "\n",
        "# Perform Hyperparameter tuning on MLP with depth 0\n",
        "avgValAccs0, avgTrainAccs0, optParameter0, optValidAcc0, optTrainAcc0 = hyperparameterTuning(\n",
        "    fashionMNIST,5,hyperparameters0)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter0)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc0)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "AGTGRySOO2WZ",
        "outputId": "994d37b3-b206-4875-ac18-4a463765ac05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e18eb6f3-b3ef-46e8-9587-52a92c3cd4ba\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e18eb6f3-b3ef-46e8-9587-52a92c3cd4ba\")) {                    Plotly.newPlot(                        \"e18eb6f3-b3ef-46e8-9587-52a92c3cd4ba\",                        [{\"x\":[0.001,0.01,0.1],\"y\":[5000,10000,15000],\"z\":[[0.7682833333333334,0.7985333333333333,0.8139666666666667],[0.8391666666666667,0.8479666666666666,0.8506833333333332],[0.8520833333333334,0.8538666666666668,0.8530833333333334]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Learning rate\"}},\"yaxis\":{\"title\":{\"text\":\"Maximum number of iterations\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 5-fold validation accuracy (ReLu, depth 0, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e18eb6f3-b3ef-46e8-9587-52a92c3cd4ba');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig0 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs0,(3, 3)), \n",
        "                                 x = np.array(learning_rates), \n",
        "                                 y = np.array(max_iters))])\n",
        "fig0.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Learning rate',\n",
        "                    yaxis_title = 'Maximum number of iterations',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 5-fold validation accuracy (ReLu, depth 0, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, height = 600)\n",
        "fig0.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYYcQJ6jXyoG"
      },
      "source": [
        "We also create an MLP with a single hidden layer of width 128 and ReLu activation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23-CD9X2X20r",
        "outputId": "d230d737-41fd-4367-ce74-9d2468a098d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.75014583 0.7554375  0.75389583 0.749125   0.75175   ] \n",
            "\tValid Accuracies:  [0.74833333 0.75616667 0.754      0.74816667 0.74833333]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.80802083 0.80647917 0.79925    0.80089583 0.80266667] \n",
            "\tValid Accuracies:  [0.80575    0.80291667 0.80766667 0.79925    0.79316667]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.001, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.82960417 0.8295625  0.83052083 0.83102083 0.82566667] \n",
            "\tValid Accuracies:  [0.8275     0.82616667 0.82625    0.82933333 0.82891667]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8698125  0.86566667 0.8654375  0.86502083 0.87010417] \n",
            "\tValid Accuracies:  [0.85841667 0.86566667 0.85883333 0.86108333 0.85725   ]\n",
            "Hyperparameter tuning: Round 4 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8875625  0.8880625  0.88622917 0.88583333 0.8859375 ] \n",
            "\tValid Accuracies:  [0.87725    0.86975    0.86866667 0.87466667 0.87733333]\n",
            "Hyperparameter tuning: Round 5 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.895125   0.89310417 0.89927083 0.8956875  0.89577083] \n",
            "\tValid Accuracies:  [0.88033333 0.87416667 0.87925    0.87341667 0.8805    ]\n",
            "Hyperparameter tuning: Round 6 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.90183333 0.89647917 0.8954375  0.89495833 0.90533333] \n",
            "\tValid Accuracies:  [0.87208333 0.87508333 0.87341667 0.87875    0.87625   ]\n",
            "Hyperparameter tuning: Round 7 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.90372917 0.91972917 0.91345833 0.924      0.9189375 ] \n",
            "\tValid Accuracies:  [0.86933333 0.875      0.872      0.88366667 0.88208333]\n",
            "Hyperparameter tuning: Round 8 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.93679167 0.93754167 0.93452083 0.93066667 0.93583333] \n",
            "\tValid Accuracies:  [0.88225    0.88508333 0.88633333 0.87466667 0.88033333]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e5bb4dd0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8817333333333334\n",
            "Average training accuracy with optimal hyperparameters:  0.9350708333333333\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters: list of different parameter combinations\n",
        "learning_rates = [.001, .01, .1]\n",
        "max_iters = [5000, 10000, 15000]\n",
        "hyperparameters1 = [dict(activations = [ReLuAc], depth = 1, widths = [128], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = m, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for L in learning_rates for m in max_iters]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 1\n",
        "avgValAccs1, avgTrainAccs1, optParameter1, optValidAcc1, optTrainAcc1 = hyperparameterTuning(\n",
        "    fashionMNIST,5,hyperparameters1)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter1)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc1)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "3TBN5jx_VTVi",
        "outputId": "752e89d2-5fca-4be9-8a57-c0a2046acd68"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1bf40b47-958c-4680-a51b-bb9a3da5994d\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1bf40b47-958c-4680-a51b-bb9a3da5994d\")) {                    Plotly.newPlot(                        \"1bf40b47-958c-4680-a51b-bb9a3da5994d\",                        [{\"x\":[0.001,0.01,0.1],\"y\":[5000,10000,15000],\"z\":[[0.751,0.80175,0.8276333333333333],[0.86025,0.8735333333333333,0.8775333333333333],[0.8751166666666667,0.8764166666666666,0.8817333333333334]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Learning rate\"}},\"yaxis\":{\"title\":{\"text\":\"Maximum number of iterations\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 5-fold validation accuracy (ReLu, depth 1, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1bf40b47-958c-4680-a51b-bb9a3da5994d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs1,(3, 3)), \n",
        "                                 x = np.array(learning_rates), \n",
        "                                 y = np.array(max_iters))])\n",
        "fig1.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Learning rate',\n",
        "                    yaxis_title = 'Maximum number of iterations',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 5-fold validation accuracy (ReLu, depth 1, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTC680i1YAO5"
      },
      "source": [
        "We also create an MLP with 2 hidden layers each of width 128 with ReLu activations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qc63XJLxtbE",
        "outputId": "dc3337f9-d462-43e4-c03c-e0932765e02b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8474 0.8489] \n",
            "\tValid Accuracies:  [0.83846667 0.84423333]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8857     0.88523333] \n",
            "\tValid Accuracies:  [0.86463333 0.86483333]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.90376667 0.90416667] \n",
            "\tValid Accuracies:  [0.87156667 0.8741    ]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.91083333 0.90333333] \n",
            "\tValid Accuracies:  [0.87996667 0.87176667]\n",
            "Hyperparameter tuning: Round 4 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.9305     0.92293333] \n",
            "\tValid Accuracies:  [0.87246667 0.86836667]\n",
            "Hyperparameter tuning: Round 5 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.94366667 0.95183333] \n",
            "\tValid Accuracies:  [0.87733333 0.87723333]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e11c8710>, <__main__.activation object at 0x7fc3e11c8710>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8772833333333333\n",
            "Average training accuracy with optimal hyperparameters:  0.94775\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters: list of different parameter combinations\n",
        "learning_rates = [.01, .1]\n",
        "max_iters = [5000, 10000, 15000]\n",
        "hyperparameters2 = [dict(activations = [ReLuAc, ReLuAc], depth = 2, widths = [128, 128], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = m, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for L in learning_rates for m in max_iters]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs2, avgTrainAccs2, optParameter2, optValidAcc2, optTrainAcc2 = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters2)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter2)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc2)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "CQqcw61sVpp8",
        "outputId": "95c3cb2f-4da9-4b81-8d4d-049a27c49067"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"fb618fd0-b092-42dc-bb8b-d720da38cd37\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb618fd0-b092-42dc-bb8b-d720da38cd37\")) {                    Plotly.newPlot(                        \"fb618fd0-b092-42dc-bb8b-d720da38cd37\",                        [{\"x\":[0.01,0.1],\"y\":[5000,10000,15000],\"z\":[[0.84135,0.8647333333333334],[0.8728333333333333,0.8758666666666667]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Learning rate\"}},\"yaxis\":{\"title\":{\"text\":\"Maximum number of iterations\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 2-fold validation accuracy (ReLu, depth 2, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fb618fd0-b092-42dc-bb8b-d720da38cd37');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig2 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs2,(2, 2)), \n",
        "                                 x = np.array(learning_rates), \n",
        "                                 y = np.array(max_iters))])\n",
        "fig2.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Learning rate',\n",
        "                    yaxis_title = 'Maximum number of iterations',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 2-fold validation accuracy (ReLu, depth 2, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters: list of different parameter combinations\n",
        "hyperparameters2a = [dict(activations = [ReLuAc, ReLuAc, ReLuAc], depth = 3, widths = [128, 128, 128], dropout_rate = 0,\n",
        "                        learning_rate = 0.1, max_iters = 10000, epsilon = 1e-5, batchSize = 32\n",
        "                        )]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs2a, avgTrainAccs2a, optParameter2a, optValidAcc2a, optTrainAcc2a = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters2a)\n",
        "\n",
        "print(\"Average validation accuracy: \", optValidAcc2a)\n",
        "print(\"Average training accuracy: \", optTrainAcc2a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIou0DLmnrrZ",
        "outputId": "cd8e2418-c144-430a-a00b-3b95cfb062a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fee2118c2d0>, <__main__.activation object at 0x7fee2118c2d0>, <__main__.activation object at 0x7fee2118c2d0>], 'depth': 3, 'widths': [128, 128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.9265     0.92703333] \n",
            "\tValid Accuracies:  [0.8775     0.87376667]\n",
            "Average validation accuracy:  0.8756333333333333\n",
            "Average training accuracy:  0.9267666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0urWfV-QbOpH"
      },
      "source": [
        "###3.2: MLPs with Tanh and Leaky-ReLU activations\n",
        "\n",
        "We now build a new MLP with 2 hidden layers of width 128, but now with `tanh` activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF8alzgQWefM",
        "outputId": "899531f4-0085-4579-f051-9c5754b955fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4e50>, <__main__.activation object at 0x7fc3e5bb4e50>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.81943333 0.82176667] \n",
            "\tValid Accuracies:  [0.81493333 0.81516667]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4e50>, <__main__.activation object at 0x7fc3e5bb4e50>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8634     0.86393333] \n",
            "\tValid Accuracies:  [0.8488     0.84843333]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4e50>, <__main__.activation object at 0x7fc3e5bb4e50>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.9054 0.9047] \n",
            "\tValid Accuracies:  [0.86986667 0.86856667]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4e50>, <__main__.activation object at 0x7fc3e5bb4e50>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.94553333 0.9435    ] \n",
            "\tValid Accuracies:  [0.8788 0.8743]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e5bb4590>, <__main__.activation object at 0x7fc3e5bb4590>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8765499999999999\n",
            "Average training accuracy with optimal hyperparameters:  0.9445166666666667\n"
          ]
        }
      ],
      "source": [
        "learning_rates = [.01, .1]\n",
        "max_iters = [5000, 10000]\n",
        "hyperparameters3 = [dict(activations = [tanhAc, tanhAc], depth = 2, widths = [128, 128], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = m, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for L in learning_rates for m in max_iters]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs3, avgTrainAccs3, optParameter3, optValidAcc3, optTrainAcc3 = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters3)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter3)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc3)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "GoGpVE5SvmYw",
        "outputId": "55b3a51f-9d9d-448d-c348-582c8774312c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"04ca2026-1f79-4783-a2ed-4c7a40ecd38d\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"04ca2026-1f79-4783-a2ed-4c7a40ecd38d\")) {                    Plotly.newPlot(                        \"04ca2026-1f79-4783-a2ed-4c7a40ecd38d\",                        [{\"x\":[0.01,0.1],\"y\":[5000,10000],\"z\":[[0.81505,0.8486166666666667],[0.8692166666666667,0.8765499999999999]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Learning rate\"}},\"yaxis\":{\"title\":{\"text\":\"Maximum number of iterations\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 2-fold validation accuracy (tanh, depth 2, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('04ca2026-1f79-4783-a2ed-4c7a40ecd38d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig3 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs3,(2, 2)), \n",
        "                                 x = np.array(learning_rates), \n",
        "                                 y = np.array(max_iters))])\n",
        "fig3.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Learning rate',\n",
        "                    yaxis_title = 'Maximum number of iterations',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 2-fold validation accuracy (tanh, depth 2, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxtSVYMEaCxy"
      },
      "source": [
        "We now build a MLP with 2 hidden layers of width 128, but now with `leakyReLu` activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMCaEyeZXYug",
        "outputId": "75464884-94b4-4f8e-b9ee-ee011dfac61b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e11c8a10>, <__main__.activation object at 0x7fc3e11c8a90>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.88046667 0.8793    ] \n",
            "\tValid Accuracies:  [0.86806667 0.85936667]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e11c8b90>, <__main__.activation object at 0x7fc3e11c8c90>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.92646667 0.92723333] \n",
            "\tValid Accuracies:  [0.8732 0.8765]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e11c8d90>, <__main__.activation object at 0x7fc3e11c8e90>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.87143333 0.8674    ] \n",
            "\tValid Accuracies:  [0.85413333 0.8563    ]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e11c8f90>, <__main__.activation object at 0x7fc3e11cc0d0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.88806667 0.90036667] \n",
            "\tValid Accuracies:  [0.86246667 0.8603    ]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e17c6910>, <__main__.activation object at 0x7fc3e17c67d0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8748499999999999\n",
            "Average training accuracy with optimal hyperparameters:  0.92685\n"
          ]
        }
      ],
      "source": [
        "# RUN THIS AGAIN WITH 10K ITERATIONS\n",
        "gammas = [.1,.5]\n",
        "learning_rates = [.01, .1]\n",
        "hyperparameters4 = [dict(activations = [activation(leakyReLu, leakyReLuD, gamma), \n",
        "                                        activation(leakyReLu, leakyReLuD, gamma)], \n",
        "                         depth = 2, widths = [128, 128], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = 10000, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for gamma in gammas for L in learning_rates]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs4, avgTrainAccs4, optParameter4, optValidAcc4, optTrainAcc4 = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters4)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter4)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc4)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "01L2Jw3dwZZS",
        "outputId": "c6296c95-5d98-440b-c29c-1260a8e9887a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"698c57ac-09f5-43e4-b6da-61d543e90a34\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"698c57ac-09f5-43e4-b6da-61d543e90a34\")) {                    Plotly.newPlot(                        \"698c57ac-09f5-43e4-b6da-61d543e90a34\",                        [{\"x\":[0.1,0.5],\"y\":[0.01,0.1],\"z\":[[0.8637166666666667,0.8748499999999999],[0.8552166666666666,0.8613833333333334]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Gamma parameter\"}},\"yaxis\":{\"title\":{\"text\":\"Learning Rate\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 2-fold validation accuracy (leakyReLu, depth 2, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('698c57ac-09f5-43e4-b6da-61d543e90a34');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig4 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs4,(2, 2)), \n",
        "                                 x = np.array(gammas), \n",
        "                                 y = np.array(learning_rates))])\n",
        "fig4.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Gamma parameter',\n",
        "                    yaxis_title = 'Learning Rate',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 2-fold validation accuracy (leakyReLu, depth 2, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig4.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MWlgUE1bXHF"
      },
      "source": [
        "###3.3: Dropout regularization\n",
        "\n",
        "We now build an MLP with 2 hidden layers of width 128 with ReLu activations, but now we perform dropout regularization to the network. This means that we randomly set a given proportion $p$ of activations to be zero. \n",
        "\n",
        "We first perform hyperparameter tuning on the dropout rate for a MLP of depth 1 and width 128 with ReLu activations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoMJJh9uUXMu",
        "outputId": "7bbf6a65-34f1-4d00-e2c9-726867bfc9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fee2118c2d0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0.1, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.93303333 0.95606667] \n",
            "\tValid Accuracies:  [0.86466667 0.87503333]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fee2118c2d0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0.25, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.95353333 0.95813333] \n",
            "\tValid Accuracies:  [0.8702     0.87766667]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fee2118c2d0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0.35, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.94553333 0.95323333] \n",
            "\tValid Accuracies:  [0.86666667 0.87916667]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fee2118c2d0>], 'depth': 1, 'widths': [128], 'dropout_rate': 0.5, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.95713333 0.94713333] \n",
            "\tValid Accuracies:  [0.8737     0.86553333]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fee1e013490>], 'depth': 1, 'widths': [128], 'dropout_rate': 0.25, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8739333333333333\n",
            "Average training accuracy with optimal hyperparameters:  0.9558333333333333\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dropout_rates = [.1, .25, .35, .5]\n",
        "hyperparameters5a = [dict(activations = [ReLuAc], depth = 1, widths = [128], dropout_rate = d,\n",
        "                        learning_rate = 0.1, max_iters = 15000, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for d in dropout_rates]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 1\n",
        "avgValAccs5a, c, optParameter5a, optValidAcc5a, optTrainAcc5a = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters5a)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter5a)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc5a)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc5a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "k7wJZgKxUXB9",
        "outputId": "e3f7afb2-13d4-40d6-df1c-a4ed300e85b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot train/test accuracies for each epoch\n",
        "plt.plot()\n",
        "plt.scatter(dropout_rates, avgValAccs5a,label='Training accuracy',c='orange',alpha=0.7)\n",
        "plt.plot(dropout_rates, avgValAccs5a,'orange',alpha=0.7)\n",
        "plt.scatter(dropout_rates, avgValAccs5a,label='Validation accuracy',c='teal',alpha=0.7)\n",
        "plt.plot(dropout_rates, avgValAccs5a,'teal',alpha=0.7)\n",
        "plt.title('Training and validation accuracies with respect to dropout rate for 1-layer MLP')\n",
        "plt.xlabel('Dropout rate')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlim(0, max(dropout_rates))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU4EhvvTUXu_"
      },
      "source": [
        "We also perform hyperparameter tuning on the dropout rate for a MLP of depth 2 and width [128, 128] with ReLu activations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV_VN_ZUcibT",
        "outputId": "da93cdc9-fe1d-4636-f9ab-6be1de7c7c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.1, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.88533333 0.8848    ] \n",
            "\tValid Accuracies:  [0.86763333 0.86096667]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.1, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.93553333 0.924     ] \n",
            "\tValid Accuracies:  [0.8772     0.86723333]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.25, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8863     0.88173333] \n",
            "\tValid Accuracies:  [0.8663     0.86873333]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.25, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.92763333 0.93306667] \n",
            "\tValid Accuracies:  [0.8742 0.8835]\n",
            "Hyperparameter tuning: Round 4 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.35, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.884      0.87613333] \n",
            "\tValid Accuracies:  [0.8643     0.86023333]\n",
            "Hyperparameter tuning: Round 5 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.35, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.92593333 0.92903333] \n",
            "\tValid Accuracies:  [0.87383333 0.87186667]\n",
            "Hyperparameter tuning: Round 6 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.5, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.88033333 0.87916667] \n",
            "\tValid Accuracies:  [0.86406667 0.86193333]\n",
            "Hyperparameter tuning: Round 7 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.5, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.93596667 0.92276667] \n",
            "\tValid Accuracies:  [0.8805     0.86846667]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e4f1f110>, <__main__.activation object at 0x7fc3e4f1f110>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0.25, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8788499999999999\n",
            "Average training accuracy with optimal hyperparameters:  0.93035\n"
          ]
        }
      ],
      "source": [
        "dropout_rates = [.1, .25, .35, .5]\n",
        "learning_rates = [.01, .1]\n",
        "hyperparameters5 = [dict(activations = [ReLuAc, ReLuAc], depth = 2, widths = [128, 128], dropout_rate = d,\n",
        "                        learning_rate = L, max_iters = 10000, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for d in dropout_rates for L in learning_rates]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs5, avgTrainAccs5, optParameter5, optValidAcc5, optTrainAcc5 = hyperparameterTuning(\n",
        "    fashionMNIST,2,hyperparameters5)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter5)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc5)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "9cWeCNZDxNZt",
        "outputId": "9725f51a-a5a7-405b-885a-a3bafff16b0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a939bc99-5118-43cd-9550-fb3d769fd01f\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a939bc99-5118-43cd-9550-fb3d769fd01f\")) {                    Plotly.newPlot(                        \"a939bc99-5118-43cd-9550-fb3d769fd01f\",                        [{\"x\":[0.1,0.25,0.35,0.5],\"y\":[0.01,0.1],\"z\":[[0.8643000000000001,0.8722166666666666],[0.8675166666666667,0.8788499999999999],[0.8622666666666666,0.87285],[0.863,0.8744833333333333]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Dropout rate\"}},\"yaxis\":{\"title\":{\"text\":\"Learning Rate\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 2-fold validation accuracy (ReLu, depth 2, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a939bc99-5118-43cd-9550-fb3d769fd01f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig5 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs5,(4, 2)), \n",
        "                                 x = np.array(dropout_rates), \n",
        "                                 y = np.array(learning_rates))])\n",
        "fig5.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Dropout rate',\n",
        "                    yaxis_title = 'Learning Rate',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 2-fold validation accuracy (ReLu, depth 2, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig5.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y22oWw0EbdEk"
      },
      "source": [
        "### 3.4: Unnormalized images\n",
        "\n",
        "We now create an MLP with 2 hidden layers of width 128 with ReLu activations, but now we train it with unnormalized images. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsDDtq6pdWSo",
        "outputId": "4d60865e-c7a2-4cb3-d10f-704e1d407def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter tuning: Round 0 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.86483333 0.8598    ] \n",
            "\tValid Accuracies:  [0.85536667 0.8417    ]\n",
            "Hyperparameter tuning: Round 1 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.8931     0.87526667] \n",
            "\tValid Accuracies:  [0.8727     0.85183333]\n",
            "Hyperparameter tuning: Round 2 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.89726667 0.4825    ] \n",
            "\tValid Accuracies:  [0.86463333 0.48236667]\n",
            "Hyperparameter tuning: Round 3 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 5000, 'epsilon': 1e-05, 'batchSize': 32}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Accuracies:  [0.10096667 0.09903333] \n",
            "\tValid Accuracies:  [0.09903333 0.10096667]\n",
            "Hyperparameter tuning: Round 4 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.09976667 0.10023333] \n",
            "\tValid Accuracies:  [0.10023333 0.09976667]\n",
            "Hyperparameter tuning: Round 5 \n",
            "\tHyperparameter: {'activations': [<__main__.activation object at 0x7fc3e5bb4bd0>, <__main__.activation object at 0x7fc3e5bb4bd0>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "\tTrain Accuracies:  [0.0996 0.1004] \n",
            "\tValid Accuracies:  [0.1004 0.0996]\n",
            "Optimal hyperparameters:  {'activations': [<__main__.activation object at 0x7fc3e5aa6650>, <__main__.activation object at 0x7fc3e5aa6650>], 'depth': 2, 'widths': [128, 128], 'dropout_rate': 0, 'learning_rate': 0.01, 'max_iters': 10000, 'epsilon': 1e-05, 'batchSize': 32}\n",
            "Average validation accuracy with optimal hyperparameters:  0.8622666666666667\n",
            "Average training accuracy with optimal hyperparameters:  0.8841833333333333\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters: list of different parameter combinations\n",
        "learning_rates = [.01, .1]\n",
        "max_iters = [5000, 10000, 15000]\n",
        "hyperparameters6 = [dict(activations = [ReLuAc, ReLuAc], depth = 2, widths = [128, 128], dropout_rate = 0,\n",
        "                        learning_rate = L, max_iters = m, epsilon = 1e-5, batchSize = 32\n",
        "                        ) for L in learning_rates for m in max_iters]\n",
        "\n",
        "# Perform hyperparameter tuning on MLP with depth 2\n",
        "avgValAccs6, avgTrainAccs6, optParameter6, optValidAcc6, optTrainAcc6 = hyperparameterTuning(\n",
        "    unnormFashionMNIST,2,hyperparameters6)\n",
        "\n",
        "print(\"Optimal hyperparameters: \", optParameter6)\n",
        "print(\"Average validation accuracy with optimal hyperparameters: \", optValidAcc6)\n",
        "print(\"Average training accuracy with optimal hyperparameters: \", optTrainAcc6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "5iYPbIbRyyNc",
        "outputId": "642be81c-6f6e-44db-9d0d-9276104825a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1a38232b-db3d-4ffa-be02-7b8d69066fa6\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1a38232b-db3d-4ffa-be02-7b8d69066fa6\")) {                    Plotly.newPlot(                        \"1a38232b-db3d-4ffa-be02-7b8d69066fa6\",                        [{\"x\":[0.01,0.1],\"y\":[5000,10000,15000],\"z\":[[0.8485333333333334,0.8622666666666667,0.6735],[0.1,0.1,0.1]],\"type\":\"surface\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"scene\":{\"xaxis\":{\"dtick\":1,\"type\":\"log\",\"title\":{\"text\":\"Learning rate\"}},\"yaxis\":{\"title\":{\"text\":\"Maximum number of iterations\"}},\"zaxis\":{\"title\":{\"text\":\"Validation accuracy\"}}},\"title\":{\"text\":\"MLP: Average 2-fold validation accuracy (unnormalized, ReLu, depth 2, batchSize 32)\"},\"autosize\":false,\"width\":600,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1a38232b-db3d-4ffa-be02-7b8d69066fa6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig6 = go.Figure(data=[go.Surface(z = np.resize(avgValAccs6,(2, 3)), \n",
        "                                 x = np.array(learning_rates), \n",
        "                                 y = np.array(max_iters))])\n",
        "fig6.update_layout(scene = dict(\n",
        "                    xaxis=dict(dtick = 1, type = 'log'),\n",
        "                    xaxis_title = 'Learning rate',\n",
        "                    yaxis_title = 'Maximum number of iterations',\n",
        "                    zaxis_title = 'Validation accuracy'),\n",
        "                  title = 'MLP: Average 2-fold validation accuracy (unnormalized, ReLu, depth 2, batchSize 32)', \n",
        "                  autosize = False,\n",
        "                  width = 600, \n",
        "                  height = 600)\n",
        "fig6.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A648RqNbmxA"
      },
      "source": [
        "### 3.5: Optimal MLP architecture\n",
        "\n",
        "After trying out various parameter, we select the MLP model with the highest test accuracy. We then compare the accuracies of the CNN model with this optimal MLP model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIOqNroaLh9y"
      },
      "outputs": [],
      "source": [
        "class GradientDescentBis:\n",
        "  def __init__(self, learning_rate=.001, max_iters=1e5, epsilon=1e-5, batchSize=32):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.max_iters = max_iters\n",
        "    self.epsilon = epsilon\n",
        "    self.batchSize = batchSize\n",
        "        \n",
        "  def run(self, gradient_fn, x, y, activations, weights, biases, depth):\n",
        "    # Train/test accuracies for each epoch\n",
        "    trainAccs = []\n",
        "    testAccs = []\n",
        "\n",
        "    # Separate data into mini batches\n",
        "    batches = mini_batches(x,y,self.batchSize)\n",
        "    norms = np.array([np.inf])\n",
        "    t = 0\n",
        "    batchIdx = 0\n",
        "\n",
        "    # While gradient norms are non-null, and iterations left\n",
        "    while np.any(norms > self.epsilon) and t < self.max_iters:\n",
        "\n",
        "      # If we have used all batches, save accuracies and make new random batches\n",
        "      if (batchIdx >= len(batches)): \n",
        "        # Save training accuracy for the past epoch\n",
        "        trainPred = np.zeros((trainData.shape[0], trainLabels.shape[1])) \n",
        "        for n in range(trainData.shape[0]):\n",
        "            _, Ztrain = feed_forward(trainData[n], activations, weights, biases, depth)\n",
        "            trainPred[n] = Ztrain[-1]\n",
        "        trainAccs.append(evaluate_acc(trainLabels, trainPred))\n",
        "\n",
        "        # Save testing accuracy for the past epoch\n",
        "        testPred = np.zeros((testData.shape[0], testLabels.shape[1])) \n",
        "        for n in range(testData.shape[0]):\n",
        "            _, Ztest = feed_forward(testData[n], activations, weights, biases, depth)\n",
        "            testPred[n] = Ztest[-1]\n",
        "        testAccs.append(evaluate_acc(testLabels, testPred))\n",
        "\n",
        "        # Make new random batches: \n",
        "        batches = mini_batches(x,y,self.batchSize)\n",
        "        batchIdx = 0\n",
        "\n",
        "      # Find weight/bias gradient on the batch\n",
        "      (X_batch, Y_batch) = batches[batchIdx]\n",
        "      weightGrad, biasGrad = gradient_fn(X_batch, Y_batch, activations, weights, biases)\n",
        "\n",
        "      # Apply gradient descent on weights and biases\n",
        "      for k in range(len(weights)):\n",
        "        weights[k] -= self.learning_rate * weightGrad[k] \n",
        "        biases[k] -= self.learning_rate * biasGrad[k] \n",
        "      t += 1\n",
        "      batchIdx += 1\n",
        "      norms = np.array([np.linalg.norm(g) for g in (weightGrad+biasGrad)])\n",
        "\n",
        "    return weights, biases, trainAccs, testAccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "J92CqtrleIAW",
        "outputId": "bd4368ff-a85f-49d0-b739-a75184175c08"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-156a469c75ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Run model on training data and get training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mfinalTrainAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Run model on test data and compute optimal test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'evaluate_acc'"
          ]
        }
      ],
      "source": [
        "# Select best hyperparameters with highest validation accuracy: Relu, depth 1\n",
        "bestValAccs = [optValidAcc0, optValidAcc1, optValidAcc2, optValidAcc3, optValidAcc4, optValidAcc5, optValidAcc6]\n",
        "bestParams = [optParameter0, optParameter1, optParameter2, optParameter3, optParameter4, optParameter5, optParameter6]\n",
        "optIdx = np.argmax(bestValAccs)\n",
        "optValAcc = bestValAccs[optIdx]\n",
        "optParameter = bestParams[optIdx]\n",
        "\n",
        "# Train model with best hyperparameters and whole training set\n",
        "hypMLP = {k : optParameter[k] for k in optParameter if k in paramMLP}\n",
        "hypGD = dict(\n",
        "    learning_rate = optParameter['learning_rate'],\n",
        "    max_iters = 20000,\n",
        "    epsilon = optParameter['epsilon'],\n",
        "    batchSize = optParameter['batchSize'],\n",
        ")\n",
        "optMLP = MLP(**hypMLP)\n",
        "optGD = GradientDescentBis(**hypGD)\n",
        "trainAccsEpochs, testAccsEpochs = optMLP.fit(trainData, trainLabels, optGD)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8qsAAZaqrec",
        "outputId": "1e7997ab-bf92-43d6-b090-24a4f2e79195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal MLP model:\n",
            "\tHyperparameters: {'activations': [<__main__.activation object at 0x7fc3e5bb4dd0>, <__main__.activation object at 0x7fc3e5bb4f50>], 'depth': 1, 'widths': [784, 128, 10], 'dropout_rate': 0, 'learning_rate': 0.1, 'max_iters': 15000, 'epsilon': 1e-05, 'batchSize': 32} \n",
            "Training Accuracies: [0.8627166666666667, 0.8831, 0.9004166666666666, 0.9044166666666666, 0.9092333333333333, 0.9144333333333333, 0.91855, 0.9014333333333333, 0.9201833333333334, 0.9337333333333333] \n",
            "Testing Accuracies: [0.8432, 0.8553, 0.8746, 0.8717, 0.8713, 0.8746, 0.8705, 0.8546, 0.8766, 0.884]\n"
          ]
        }
      ],
      "source": [
        "print(\"Optimal MLP model:\\n\\tHyperparameters:\", optParameter, \n",
        "      \"\\nTraining Accuracies:\", trainAccsEpochs,\n",
        "      \"\\nTesting Accuracies:\", testAccsEpochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_j3SsXIeeCf"
      },
      "source": [
        "We plot the optimal MLP's training and testing accuracy as a function of the training epoch below. Note that one epoch corresponds to one forward/backward pass of the whole training set through the network. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WBQBruRjttc-",
        "outputId": "58f338c1-9a65-48e8-b7a0-092a45759083"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot train/test accuracies for each epoch\n",
        "epochsMLP = list(range(len(trainAccsEpochs)))\n",
        "plt.plot()\n",
        "plt.scatter(epochsMLP, trainAccsEpochs,label='Training accuracy',c='orange',alpha=0.7)\n",
        "plt.plot(epochsMLP, trainAccsEpochs,'orange',alpha=0.7)\n",
        "plt.scatter(epochsMLP, testAccsEpochs,label='Testing accuracy',c='teal',alpha=0.7)\n",
        "plt.plot(epochsMLP, testAccsEpochs,'teal',alpha=0.7)\n",
        "plt.title('Training and testing accuracies with respect to number of epochs for optimal MLP')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlim(0, max(epochsMLP))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_dRGQH5yKlA"
      },
      "source": [
        "### 3.6: CNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlL6HpL1yNFg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "trainY = tf.keras.utils.to_categorical(trainY)\n",
        "testY = tf.keras.utils.to_categorical(testY)\n",
        "\n",
        "# Calculate training set average and standard deviation\n",
        "trainXAvg = trainX.mean(axis=0)\n",
        "trainXsd = trainX.std(axis=0)\n",
        "\n",
        "# Normalize by setting mean 0 and std 1\n",
        "trainX = (trainX - trainXAvg)/trainXsd\n",
        "testX = (testX - trainXAvg)/trainXsd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFFxcjsWyNnL"
      },
      "outputs": [],
      "source": [
        "def buildCNN():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uZXvHQhYyS7u",
        "outputId": "d2eac740-590e-4a0a-bd72-2f1cef08640c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.3629 - accuracy: 0.8701 - val_loss: 0.3177 - val_accuracy: 0.8868\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.2258 - accuracy: 0.9169 - val_loss: 0.2398 - val_accuracy: 0.9159\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 102s 54ms/step - loss: 0.1691 - accuracy: 0.9378 - val_loss: 0.2389 - val_accuracy: 0.9174\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.1324 - accuracy: 0.9500 - val_loss: 0.2501 - val_accuracy: 0.9189\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0994 - accuracy: 0.9633 - val_loss: 0.2873 - val_accuracy: 0.9174\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0759 - accuracy: 0.9717 - val_loss: 0.2938 - val_accuracy: 0.9158\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0596 - accuracy: 0.9784 - val_loss: 0.3269 - val_accuracy: 0.9189\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0477 - accuracy: 0.9826 - val_loss: 0.3581 - val_accuracy: 0.9166\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0424 - accuracy: 0.9842 - val_loss: 0.4346 - val_accuracy: 0.9108\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0330 - accuracy: 0.9876 - val_loss: 0.4132 - val_accuracy: 0.9217\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.5096 - val_accuracy: 0.9110\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.4651 - val_accuracy: 0.9192\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.4667 - val_accuracy: 0.9189\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.5078 - val_accuracy: 0.9184\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.5610 - val_accuracy: 0.9140\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0205 - accuracy: 0.9932 - val_loss: 0.5773 - val_accuracy: 0.9180\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.5595 - val_accuracy: 0.9214\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.6128 - val_accuracy: 0.9155\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.5724 - val_accuracy: 0.9186\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.6138 - val_accuracy: 0.9172\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb8AAAEWCAYAAAD2AJlUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3xeVf3H399nZO/VNKNN96R0pK1ltazKFFErG6soWxTB9UNREQUVEH+Wn4qAIKIsBREZhUJbKCsdlO6dZrRJm50nT/LM8/vj3LRPQ8aTJzs977zyeu46537vufeez/medUUphcFgMBgMxxO2gTbAYDAYDIb+xoifwWAwGI47jPgZDAaD4bjDiJ/BYDAYjjuM+BkMBoPhuMOIn8FgMBiOO/pN/ETkVRH5Sm8fO5CISLGInDXQdgxlROQKEVk+QOf+HxF5pJP9S0Xk3f60yRAeA31vROQGEakUEZeIpA+UHSH29Ep6iOYvIlIrIh/1hm2DlU7Fz7qxrf9BEWkOWb+iOydSSp2rlHqit48drIjI4yJydy/EUyAiSkQcvWHXYEMp9ZRSavEAnfuXSqmvw/BPZ+i6sCYii0SkrD9tGoqIiBN4AFislEpQSlUPtE29yCnA2UCeUmpeb0QoIlEi8lMR2SUiTdZz+JiIFFj7V4pIi4jkh4Q5S0SKQ9aLReSQiMSHbPu6iKyM1K5Oxc+6sQlKqQSgBLgwZNtTIUYM2wzD0DXm/n8akyZDhwju1QggBtjSB+YMNKOBYqVUU3cDdpKOzwOfAy4HkoETgXXAmSHHNAE/7uIUduBb3bWrQ5RSYf0DxcBZ1vIioAz4PlABPAmkAi8Dh4FaazkvJPxK4OvW8lLgXeA+69h9wLkRHjsGWA00Am8CDwF/6+AawrHx58AaK77lQEbI/quA/UA1cEdomrQ5z7WAD/ACLuA/1vYc4J/W+fcBt4SEmQesBRqASuABa3sJoKx4XMCCds43D3gfqAMOAsuAqJD904A3gBor7v+xttuB/wH2WNe7DsgHCqxzOjq5J2uA31ppcTcwDnjLWq8CngJSQsLnA/+yrr0aWBZ6f0OOmxxi6w7gyyH7zgO2WraWA7d3cJ/3A3Os5Susa5lmrV8DvGgt/7T1WWkvneni2evgHfk+8AngARzAZ4D3rHuzEVgUcvxSYK91PfuAK9qk7zKgHtgOnBkSLhl41LrX5Vb620P2fwPYZsW7FZiNfkeDQLN1fd9rY3u8tS8YkgY5QDTwIHDA+n8QiO7g+jtNL9q8L23Sv8BK/68CpVb464G5VnrWYT0zPU0j2nl+27mWdq8bmIjOqFuflbc6SIvO7vtK4B7gI/T7/m8gLWT/59DCWmcdOyXc96iTtF9KO89aG5uvAVqAgHVtPwt5nnaj38mXgJyQMAq4CdgF7GsnzrPQz1V+J+/NSuAnlm3jQsIVt3l2fmDZkGJt+zqw0loW634estJ0EzC9o3MqpXokfn7gV9YDEQukA18E4oBE4DmsTKaDzNNnJaoduMF6wCSCY9+3bngU2mVvoGPxC8fGPegHPNZav9faN9V6IE6zrvkBKw0+JX7W8Y8T8lKhvex1wJ2WrWPRD+NnQ67jKms5AfhMm0zB0cm9mYN+2RzW8duAb1v7EtEZwG3o0moiMN/a913rIZlkPTwnWmn0qXO2c0/8wDetc8YC49HVJdFAJrpA8qB1vB2dAfwWncnGAKeEvrQhGXApOgN0ALPQQjrV2n8QONVaTgVmd5AefwVus5Yftu7pDSH7bu0k8w295qV08ux18I58jM6gYoFcdAZ1nnX/z7bWM61rbQAmWWFHclSgW9P3VsAJXILO4NOs/S8Af7LiyEJnotdZ+5agM/u51j0dD4xu+w53YP8ioKzNtruAD6zzZKIz9J93EL7T9Gp7/g7S/4/W87EYnRG/aJ07F52xLeyFNGoNe+T5bedaOrxuungnO7vvIe9SOTDdsu+fIenQKq5nW9f1PbTwRNH1e9Ru2tPJs9bBPQwtjJ6Bfgdno9/t3wOrQ/YrdGE1rYN0vBdY1YW2rEQL2QMh6dCe+J2FFv67rW2h4vdZdP6aYl3zFGBkp+ftbGc7L3ao+HmBmE6OnwnUdpJ57g7ZF2clYnZ3jgVGoR/iuJD9f6MD8QvTxh+FrN8IvGYt3wk8HbIv3kqDcMVvPlDS5pgfAn+xllcDPyPE0wznRevg3N8GXrCWLwM2dHDcDuCidrZ/6pzt3JOSLmz4fOt50V7U4faugWPF7xLgnTb7/wT8xFouAa4Dkro49zXAS9byNvRL8rS1vh9LNAlP/Dp8Tjt4R74Wsv594Mk2x7wOfMV6furQhbHYNscspY3IojPvq9BVbp7QMNY9fjsk/m91Yl93xW8PcF7I+mcJyZTasbuz9/qY83eQ/rkh+6uBS0LW/8nRQl1P0mgpXT+/HV53e89Km7Ad3veQd+nekH1T0XmJHV3192zIPhtaKBfR9XvUUT7Z4bPW2ftorT8K/DpkPQEtsgXWugLO6CS+PxOSb3ZwzEr0O5qJLsBMo2Pxm24dk8mx4ncGsBPtBNg6O1/rf096ex5WSrW0rohInIj8SUT2i0gDOjNPERF7B+ErWheUUm5rMaGbx+YANSHbQHsO7RKmjRUhy+4Qm3JC41a6Trw7Dd2jgRwRqWv9R1c5jrD2X4Mu9W0XkSIRuSDciEVkooi8LCIV1nX9EsiwduejX+T26GxfVxyTziIyQkSeFpFyy4a/tbFhv1LK30Wco4H5bdLoCvQLDPrlPQ/YLyKrRGRBB/GsAk4VkZHoDOVZ4GSrgT0Z7Z2FS3eeUzg2XUYDS9pczynoEmkTWuyvBw6KyH9FZHJI2HJlvdUW+9HP4Gi0R3AwJM4/oT0U6Nk9bY8c69xt7eiI7qZXWypDlpvbWQ+NK9I0gk7yCYvuXncoHd73Ds6/37I3o+15lVJB69hcun6P2k37MJ61zmhrjwud7+V2cC1tqebY6+4QpdRhdDX2XZ0csxndXPWDNtvfssI+BBwSkYdFJKmz8/VE/FSb9dvQ1WfzlVJJ6OpB0C5oX3EQSBORuJBt+R0dTM9sPBgat3XOzro4t02fUnSdeErIf6JS6jwApdQupdRl6Bf0V8DzVs+mtvG0xx/QbR4TrOv6n5BrKkVXsbZHKbqtri2tjd2h6Zrd5pi2dv3S2naCZcOVbWwYFUbHglJ0FUloGiUopW4AUEoVKaUuQqfRi2hR+xRKqd3ogss30VU0DeiM4Vp0qTbYXrAubAuX0HhK0R5A6PXEK6Xutex8XSl1Njpz2I4uJbeSKyKhz+UotKdTivZqMkLiTFJKTQs5Z3v3tK1t4e4/gM7M29oRCU10/kx1l0jTCLpOi55cd6f33SI0nxqF9qaq2p7Xur58tPcX7nv0Kbp41jqjrT3x6HyvPDT6TsK/CcwTkbwwz/cb4HR0U05H/ARdvRsqwCil/lcpNQftSU9EN+t0SG+O80tEl8zqRCTNMrBPUUrtR3cS+anVnXYBcGEf2fg8cIGInCIiUejSSWfpV8mxovMR0Cgi3xeRWBGxi8h0EZkLICJXikimlTHXWWGC6GqOIB0LWOt1NQAuq0R3Q8i+l4GRIvJtEYkWkUQRmW/tewT4uYhMEM0MEUm3SmDlwJWWnV+j4ww11AYXUC8iuRz74H2ELjzcKyLxIhIjIie3E8fLwEQRuUpEnNb/XBGZYt3fK0QkWSnls663PRFrZRVws/ULumoldL0t4aRzd/kbcKGIfNZKxxjRwwnyLE/5Iisz8aDTLvR6soBbrDRYgm7DeEUpdRDdEet+EUkSEZuIjBORhVa4R4DbRWSOdU/Hi0hr5tX2mWxLJZAuIskh2/4B/EhEMkUkA139/7cI0+Nj4FLrmgqBL0UYTyuRplE49OS6O7zvIcdcKSJTrUL0XcDzSqkAukB3voicKXpIxW3o5+M9wn+PjiGMZ60z/gF8VURmikg0upD7oVKqOJzASqk30W2CL1jPpMPKg6638pW2x9cB96PbOjuKczfwDHBLyDXOFZH5Vpo1oduLO73G3hS/B9GN/FXohuLXejHuzrgCXRfe2uvwGfQNbo+IbVRKbUH3avo7+gGsRfd47YhHgalWtceL1oN9AbqdcZ9lwyPoajiAc4AtIuICfgdcqpRqtqovfgGsseL6TDvnuh3djbgRXaJ7JsTuRnTj+YVo72cXumQFuoH5WXRG0WDZHGvt+wZawKrRdfDvdZFEP0M3itcD/0U3TLfaELDOPx7dbleGroY5BsvWxcCl6BJnBUc7VYFuzykWXa16Pfred8QqtCCv7mC97bnDSeduoZQqBS5Ce+KH0SX376LfOxvwHfR11gALObbQ8iEwAf2c/AL4kjo6nuxqdAeIrejn8HmsqiWl1HPW8X9HPw8vojsjgO5h+CPr+m5vx97t6Mxur3VMDvqdWovucbkJWG9ti4QfowtRtejn5e8RxtNKRGkUJhFfdxf3vZUn0f0CKtAdV26xwu5A15r83rquC9FDzLzhvkft0NWz1tm1vIm+b/9E53vj0O9nd/gS8Ao6X6oHNgOFaK+wPX6H7nHaGXeh2zJbSULnfbUc7ZH/m84iaO2FNWwQkWeA7UqpPvc8DYa+QESWojsXnTLQthh6H9EDs/+mlOpwdiFD3zPk5/a03N1xVtXGOegS14sDbZfBYDAYBi/DYRaKbHQVWzq6GuAGpdSGgTXJYDAYDIOZfq/2FJHH0G1fh5RS09vZL+g63/PQPfaWKqXWW/u+AvzIOvRuNcTn/zQYDAbDwDAQ1Z6Pozt3dMS56EbsCeiu6X8ACOmdOR89nddPRCS1Ty01GAwGw7Ck36s9lVKrxZrNuwMuAv5qDV79QERSRA9WXgS8oZSqARCRN9Ai+o/OzpeRkaEKCjo7ncFgMBjasm7duiqlVOZA29FXDMY2v1yOnTGgzNrW0fZPISLXor1GRo0axdq1a/vGUoPBYBimiMj+ro8augz53p7toZR6WClVqJQqzMwctgUXg8FgMETIYBS/co6d+ifP2tbRdoPBYDAYusVgFL+XgKutqZk+A9Rb0xW9DiwWkVSro8tia5vBYDAYDN2i39v8ROQf6M4rGSJShu7B6QRQSv0RPQ3OeehvWLnR33ZDKVUjIj8Hiqyo7mrt/GIwGAwGQ3cYiN6el3WxX6Hn0Gxv32PAY31hl8FgMBiOHwZjb0+DwWA4LllVXMyyoiL21dYyJjWVm+fOZaEZqtUnGPEzGAyGXqCnwrWquJjbli8nPiqKEQkJHGpq4rbly7l/8eKw4+kN8WyNg8zMKd0KOMQYdl91aEthYaEy4/wMhuFNbwhPd8I3ewPUNXupbfJR5/by3v5y/rJhE05x4rQ58Cs/3qCPK2ZMZ9bIEcRG2Yl12omLchAbZSPGaQdRBJQfT8BHk8/Hra+/TpXbTZTdjohgE6HF7yctNpZfnXUW0XY7MQ4H0Q7HMcsxDgd2EVbv339EPBOionB5vTR5vd0Wz9Y4Vt9+e72qqkoJOxGHGEb8DAbDkCY0w+4s01dK4fEH8fiCePwBWqzfNSVl/Pb9D4m2O4m2OXF7gjR7g5w+ehxJzljq3D5q3V792+SlptmDxx9AoVAEQRStf6AISgBFkCABlOhfvS1AUIJHfkM/gG63CYFgEBE45tv0gFIQ49CVdCrkWpS1oXVbIAAg2LABQlKSn6D4iHU6OWvMGBQQVAqlFMGQOI5sU4p3S0po8ftx2GwcvOeeYS1+ptrTYDD0K0opymqb2Xawge0VjWw72MCOikaafQFsIthsYBPBLoKIFgab5QnZbGAXQaHwKg/NqoU9dYdpVgGC0khrWV4F4aK/vEyU3UEgCIGgInhMOV8QdXRZ0/oNbIUSxZOb1xLltOG0Cw472O3giAFHvI1kuw2nXe9z2m1sOlRBlMOOTXR0Susg/kCQ0wvGEG13EmVz4LQ5cIgdB3Zs2BFsSNCOCtpYta8Ejw+c4gQgSBBf0E+Uw0ZhzkgUigABgkppYUURUEGCBAmqIB+Ul+G0yxEhjnXasdttuLxexqelYRM54lEKHLPcum9NaSkjEhKwiXCwT5+CgceIn8FgiJiuqgvdXj87KhrZdrCR7RUNWvAONtLo8QPay8lKjMJrc+MOekiIimZSejqZcfEEFQSDima/l3qvm3qfm0a/m0avG1eghaAKohTUBz1ESRRRKgYRQUSBHfxBP9NGZGC3Sci/Fk+bDWw2wWET3tq3lxinQ3tdKOx2wWZTuH0+bj9pAVF2e5f/d65cSV1LC4lRUdhtNhw2G26fj+yEBJ5bsiTMtMzuUbXlkuee41BTE0nR0Ue2NXg8nBAfz3dPPjksG1bs23ckjk/CCjF0MeJnMBzHBIOK+mYfNkscHJaX5bAJNpt0Gra1ujHO6SQtNo7S6iZu/NdKzsqfjMdjZ/tBF/tr3Ee8sYRoB5OzE/n8rFwmj0xkysgkDntquOPtFSRFRZHtdFLT3MC6phIuHjWFaLud4vp6apqbIQpigZyYGMakjGZMaioFKSmMSUnhO8uXU+V2fyrTz4pP4bklX+oyDToSjaz4eG5dsCCsdLzztNO4bflyFLqK0uX10uzzcfPcuWGFB1hYUMD9ixcfW5hYtCjs9rqb587ltuXLAY4Rz5sXLQrbhtA4hjumzc9gOA4IBBVltW52VbrYdcjFrkONrC+tpqS6mWCwfZET0V5Sq9ckNoUSHwGbF794qfc24RMvAfERDB4bNtZpJyHGQWK0k+RY/R8X5cBhs2G32Y5Ua67av58Wv58oux2P348C/MEgMQ4HX5wyhTEpKVrkUlMZk5JCckzMp+wMt82vI3oaPjSegR6m0Ju9PZ+/6Sa3OnQovm8sHXiM+BkMwwh/IEhJjZtdh1zsPuRiV2UjOytd7DnswuM/qlCp8Q5cQRcxMUHiYwRPIIDHH+CCCRPISUykuqWZ6uZGalrc1HibqG1x0+Bt1q1JVieLKlcLMbZooiQKp82OMyqAwxmkKejm3rPOIKgUAaUIBINHloNt1n/z3nskREUBEGW3E+d0EuNw0NDSwrrrrgv7uvu7t+fxgIisU0oVDrQdfYWp9jQYhhABq5qypsnDit0lPLt5BwdrPcQQR7wtnsp6H94QkctNiWV8VgInjUtnwogEJoxIpCAjjq++9AIVLhcxDgfeQADl8+FuaeH5ksNMz8o60oPQ7hTGpyWSn5TFqORkRiUnk5+cTE5iIlf861/tVhdOiR/JJdOnh3U975SUtBvH2LS0bqXLwoKCHolVT8Mbhh5G/AyGAcTjD1DT5KXa5aWmyUut++hyjdtLTehyk5c6t/eYXouKKBRO3E4v1Y5DzB2XzrScdFLibMTGCJ6AjwZPM3WeOlZUeHhhv4cmn4939u8n2nH09Rc4IoSXTZ9+ROhGJibisLU//31vtzFFGofBEAmm2tNg6ENafAHKapsprXFTWuvWvzXNbKuso6y2mUCg/fY2m0BafBSpcVEkxdqIjVXYHUFs9gABm493SvfRFGgBCerejaLbyqLtdubk5ADgsNlIjo4mOTqaJOs/OSaGpOholn30ES6vl+SYGJw2GzEOB41eL1nx8WH3ToTebWMyVY6DC1PtaTAYOiQQVFQ0tFBSrcWtrMZNaW0zJTVa6A41eo45PtphIy3BQZWngbhERWyM4FVeWoLNfGn6RArSkmgOeGj0tnDI3URlUxUurxdvSBzxdidu5SI1PpYYhwOnzYbTbscmQn1LC3++8EKSoqOJdTiQtiOmLUYmJBzxuKIt4YvE4+qN6kJT5WgYCIz4GQzdoMnjZ9XOw7y2uYKNZXUcqGvGFzhae2ITGJkcS35aLAsnZpKfFseotDjy02LJT40jIyGai599BldtLR6/nzq/H28ggD8Y5LHNtczJycFps5EVH092QgKT0tPJTkhgREICI+LjGZGQQEJUVIfd86dkZpKdkNDldfS0W73BMNQx4mcwdEG928eK7ZW8urmC1TsP4/EHSYuPYsHYdM4/YST5aXHkp2qBy0mJxWn/dBtZpcvFmtJ9vF9Wxqri4iNzMiZFRxNtDZRu9Hh44vOfJzUmpkOPrZXeaCszHpfheMaIn8HQDocbPbyxtZJXNx/k/T3V+IOK7KQYLps3is9Oy2ZuQSqOdkQulNL6et4rLeW90lL21tUBMDYlhckZGSggMy7uiMg1eDzkJyeTFhsbln3GczMYeoYRP4PBoryumdc2V/D65gqK9tegFBSkx/H1U8dyzvRsZuQmY7MJq4qLuexfb32qg4ZSij21tbxvCV5ZYyMAUzIy+NrMmSzIzyc7IeHIoOpGr7dHPRyN52YwRI7p7Wk4rtl72MWrmyt4fUsFn5TVAzA5O5FzpmdzzvRsJo1IPKYKsu1sII0eD9VuN+dNmEBNczOH3G5sIpyQlcVJ+fl8Ji+vXW/O9HA0DHaGe29PI36G4wZfIEhpjZu9h5vYWFbH61sq2FnpAmBmfgrnTM/ms9OyGZPR8YxOX3jmGcoaGnDYbDR6vdQ2N9Ps9xPjcHDdnDmclJ/PvNzcYzqiGAxDkeEufqba0zCsUEpxuNHDnsNN7KtqYu9hl/6taqKkxk3gyAhxRWJCkCtPzuXGU6eSk3LUOwsEgxxqauJAYyNlDQ1Hf10u3tq378jgcLsIyTEx5Ccn4/H7uXPhwgG4YoPBEAlG/AxDEpfHT3FVE3taxc0Su31VTbisz+WAHlc3JiOeKSMTmZ4fy9tlO0mIE5LjBZffwwslpaRu9ZAeF3dE6A66XPhDZmqOdzrJS0piRlYW2w4fpsXvJz0ujhiHA5sIDR4PeUlJA5EMBoMhQoz4GYYM5XXNPP1RCS9sKKestvnIdhHISY5lbGY8X5ydy9jMBMZmxjMmI56c5Ngjn+b50rPPEpvUQqPPR2lVC/5gEH8wyP3vv8/8vDxGJiSQm5jIvNxcchMTyUtKIicxkaTo6CPtfrNHjuS25cuPiGODx2Om4zIYhiBG/AyDmkBQsXrnYZ76cD9vbT+EAhZOzOSyeaMYmxHPmMx4CtLjiXHaO4yjxe9nZXEx7+zfD9andFJjY4lzOom2xtc9v2QJ9g7msAzFDDEwGIYHAyJ+InIO8DvADjyilLq3zf7RwGNAJlADXKmUKrP2/Ro4H7ABbwDfUsO9185xyKHGFp5bW8bfPyyhvK6ZjIRoblg0jkvnjiI/LS6sOIrr6nh11y7eLi6m2e8nMTqaWKsKs3Wy5gaPh4kZGWEJXytmiIHBMPTpd/ETETvwEHA2UAYUichLSqmtIYfdB/xVKfWEiJwB3ANcJSInAScDM6zj3gUWAiv7y35D36GU4v091Tz1YQmvb6nAH1ScNC6d/zlvCmdPHUGUo2uB8gYCrCkp4dXdu9lWVYXTZuOUUaM4d/x4Kl0ubn/jDdw+n/mCgMFwnDMQnt88YLdSai+AiDwNXASEit9U4DvW8tvAi9ayAmKAKPRXWJxAZT/YbOhD6txenl+nvby9VU0kxzr5ykkFXD5/FOMyu56nEuBAYyOv7d7Nm3v30uj1kpOQwDWzZnHmmDEkWsMOpmRmmipLg8EADIz45QKlIetlwPw2x2wEvoCuGr0YSBSRdKXU+yLyNnAQLX7LlFLb2p5ARK4FrgUYNWpU71+BoccopVhfUsdTH+7n5U8O4vUHmT0qhfuXnMj5M0Z22IYXOjh8dEoKpxcUUOFysbGyErsIn8nL49zx45kxYkS782OaKkuDwQCDt8PL7cAyEVkKrAbKgYCIjAemAHnWcW+IyKlKqXdCAyulHgYeBj3Ivd+sNnSJy+PnxQ3lPPVhCdsONhAfZWfJnDyumD+aqTmdDxdonV3FabfjDwZ5t6SEFXv3clJ+PktnzuSssWPDnhvTYDAc3wyE+JUD+SHreda2IyilDqA9P0QkAfiiUqpORL4BfKCUcln7XgUWAMeIn2HwoZTihQ3l3P3fbdQ0eZkyMolfXDydi2bmkhAd3mP4vx99RKPXS31LCwApMTHEO53EOZ18edq0vjTfYDAMMwZC/IqACSIyBi16lwKXhx4gIhlAjVIqCPwQ3fMToAT4hojcg672XAg82F+GGyJjf3UTd7ywmXd3VzFrVAp/vrqQ2aNSuvxsTygfV1SwurgYm81GRlwcuYmJRDscBJWi2PpigsFgMIRLv4ufUsovIjcDr6OHOjymlNoiIncBa5VSLwGLgHtERKGrPW+ygj8PnAFsQnd+eU0p9Z/+vgZDePgCQR55Zx8PvrkTp93Gzy+axhXzRx8ZdB4O9S0tPLphA28XF5MYHU1qbCw5iYlH9ru8XsakpvaF+QaDYRhjJrY29AkbSmr54b82sb2ikXOmZfPTz00jOzkm7PBKKd4uLuaR9etx+3x8aepUsuPj+cGKFUe+qNA6VOH+xYtNJxaDoZcxE1sbDN2gscXHfa/v4K8f7GdEYgx/umoOn52W3a04DjY28lBRERsrK5mcns7N8+YxOiUFgPvtdjNUwWAw9BgjfoZeY/mWCu789xYqG1u4+jOjuf2zk0iMcYYd3h8M8sK2bTy9ZQsOm40bCgs5d/z4Y9oGzVAFg8HQGxjxM/SYivoWfvrSFl7bUsGkEYn835WzmT2qe+1wO6qqWPbRRxTX13NSXh7XFRaaYQsGg6HPMOJniJhgUPHUh/v59Ws78AaCfO+cSXzj1LE47eHPk+n2+Xhy40b+u2sXabGx/OjUU5mfl9d1QIPBYOgBRvwMEbGjopEf/usT1pfUcfL4dH7x+RMo6OQL6HDs7CxjUlM5vaCAj8rLqWlu5oKJE7lqxgxineFXkxoMBkOkGPEzdIsWX4Dfv7WLP63aS2KMgwe+fCIXz8rtcsxe6+ws8VFRpMbGsvbAAd7Ys4czxozhvsWLmZie3k9XYDAYDEb8DN2gqLiG7z63keJqN1+YncuPzp9KWnxUWGGXFRUR53TS4vezq7oaBeQkJiIiRvgMBkO/Y8TP0CVKKZ54r5i7/7uNnJRY/nbNfE6ZkNGtOPbU1NDi91Pd3ExydDSjU1KIstvZb2ZnMRgMA4ARP0OntPgC3PHCZv65vowzJ2fx20tnktSN4QsAh5uaaPR6qWluZnRy8hGPr8HjMbOzGAyGAcGIn6FDDtQ1c/3f1vFJWT23nDmBb1JPw8cAACAASURBVJ85oVtTkwFsqqzkV2vWkJ+UhEOExOhoFNDo8ZgPyRoMhgHDiJ+hXT7YW81NT63H4w/y8FVzWNzNWVqUUry8cyePbNhATkICT158MbtraszsLAaDYVBgxM9wDKHte6PS43j4qkLGZ4X3NfVWvIEAD330EW8VFzM/N5fvLFhAnNNJblKSETuDwTAoMOJnOEJo+95ZU7J44JLI2vd+8c477Kmt5YoTTuCSadO69ekig8Fg6A+M+BmAY9v3vnXmBL4VYfvevWvW4A8GufO005ibm9tH1hoMBkPPMOJnOKZ9789XF3L21BHdCq+U4j87d/Ko1b73o9NOIzcpqY+sNRgMhp5jxO84prfa95Z99BFvt2nfMxgMhsGMEb/jlGPb90bwwCUnmvY9g8Fw3GDE7zgktH3v22dN4JYzTPuewWA4vjDid5zR2r7n7Wb7XusXGfbW1BDjdCLAjBEjuOPUU037nsFgGHIY8TtOUErxuNW+V5Aex8NXFzIuM7z2vdYvMsQ6nbj9forr64mx2/mx6dhiMBiGKOF/ddQwpPnDqj387D9bOX1SFi/edHLYwgdHv8hQ6XJRa83POS4tjUc2bOhDiw0Gg6HvMJ7fccCqnYf5zes7+NyJOTx4ycxut+/tq63FFwxS7/FQkJJCVnw8QaXYV1vbRxYbDAZD32I8v2FOSbWbW/6xgUkjEvnVF2d0W/gAEqOjKWtoICs+nqx4/bV2l9drvshgMBiGLAMifiJyjojsEJHdIvKDdvaPFpEVIvKJiKwUkbyQfaNEZLmIbBORrSJS0J+2DyXcXj/XPrkWgIevKiQ2yt7tOErr61FK4bTZSImJIagUDa1fZJg7t7dNNhgMhn6h38VPROzAQ8C5wFTgMhGZ2uaw+4C/KqVmAHcB94Ts+yvwG6XUFGAecKjvrR56KKX4wT83saOykd9dOpNR6XHdjqPJ6+Xu1avJT07m4QsuIDshgUqXi6z4eO5fvNhMUm0wGIYsA9HmNw/YrZTaCyAiTwMXAVtDjpkKfMdafht40Tp2KuBQSr0BoJRy9ZfRQ41H393HSxsP8N3PTmLRpKxuh1dK8cD771PZ1MQvzjiDaVlZfG7y5D6w1GAwGPqfgaj2zAVKQ9bLrG2hbAS+YC1fDCSKSDowEagTkX+JyAYR+Y3lSR6DiFwrImtFZO3hw4f74BIGN+/tqeKeV7fz2WkjuHHRuIjieGbLFj46cIBrZs1iWlb3xdNgMBgGM4O1w8vtwEIR2QAsBMqBANpTPdXaPxcYCyxtG1gp9bBSqlApVZiZmdlvRg8GDtQ1882/b6AgPY77lpwY0XRjReXl/H3TJk4vKOCCiRP7wEqDwWAYWAZC/MqB/JD1PGvbEZRSB5RSX1BKzQLusLbVob3Ej5VSe5VSfnR16Oz+MXvw0+ILcP3f1umvr19dSGI35+oEONDYyP3vv8+YlBRunjfPzNVpMBiGJQMhfkXABBEZIyJRwKXAS6EHiEiGiLTa9kPgsZCwKSLS6s6dwbFthcctSinu/PdmPimr57eXzOzWIPZWWvx+7l69GpsId5x2GlH27vcONRgMhqFAv4uf5bHdDLwObAOeVUptEZG7RORz1mGLgB0ishMYAfzCChtAV3muEJFNgAB/7udLGJQ89WEJz64t45Yzxnf7e3ygxfPBDz6grKGB75188pHxfAaDwTAcGZAZXpRSrwCvtNl2Z8jy88DzHYR9A5jRpwYOMdbtr+Fn/9nC6ZMy+fZZkbXR/WvbNtaUlvLVmTOZmZ3dyxYaDAbD4GKwdngxhMmhhhau/9t6clJiefCSWRHN4PJxRQVPbNzIKfn5XGyGMxgMhuMAM7fnEMbrD3LDU+txtfj52zXzSY7rfgeXSpeLX69Zw6jkZL71mc+YDi4Gg+G4wIjfEObnL29l3f5all0+i0nZid0O7/H7+eU77xBUijtOPZUYh3kcDAbD8YGp9hyiPLe2lCc/2M+1p43lghk53Q6vlOKhoiL21dVx24IFjEzsvngaDAbDUMWI3xDkk7I67nhxMyePT+d7n50UURwv79zJ28XFXH7CCczNbTvBjsFgMAxvjPgNMapdHq5/ch2ZCdH8/rLZOOzdv4WbDx3ikQ0bmJ+byyXTpvWBlQaDwTC4MY08Qwh/IMg3/7GBqiYv/7z+JNLio7odR5Xbzb3vvsvIhARuNR1cDAbDcYoRvyHEr17bznt7qrlvyYmckJccdrhVxcUsKypib00NjV4vOYmJPHnxxcRHdV88DQaDYThgxG+I8O+Py/nzO/u4esFovjQnr+sAFquKi7lt+XLio6JoCQSobm7GJsLe2lryk8MXUIPBYBhOmDa/IcCmsnp+8M9NFI5O5Ufnt/3ub+csKyoiPiqKZp+PKreb/KQkRiQksKyoqI+sNRgMhsGP8fwGOQfqmrnmiSLS4qP4vytnE+XoXnllX20t0Q4HJfX1pMTEkJeUhLK2GwwGw/GK8fwGMY0tPr72eBHN3gCPLZ1LVmJMt+PIio9nZ3U1sU4n41JTERFcXi9jUlP7wGKDwWAYGhjxG6T4A0Fu/vsGdh1y8X9Xzo5oBpdqt5ugUiilGJmQgIjQ4PHQ5PVy89y5fWC1wWAwDA2M+A1ClFL85KUtrNp5mLs/P51TJ3T/a/Qtfj93rVpFYnQ0y849l9ykJCpdLrLi47l/8WIWFhT0vuEGg8EwRDBtfoOQR9/dx1MflnD9wnFcNm9Ut8MHleLXa9awr66OOxcupDAnh0tPOKEPLDUYDIahifH8Bhmvba7gF69s47wTsiOeuuyR9espOnCA6wsLKczp/ryfBoPBMNwx4jeI2Fhax7ef2cCJeSk88OWZEX2b7z87dvCfnTu5aNIkzpswoQ+sNBgMhqGPEb9BQlmtm2ueWEtGQjR/vrqQGKe923F8VF7On9evZ35uLl+bNasPrDQYDIbhQcTiJyIXiogRz16gwRrS4PEH+MvSuWQmRnc7jj01Nfx6zRrGpaZy+0knYTNzdhoMBkOH9ES8LgF2icivRWRybxl0vOELBLnpqfXsPdzEH6+cw4QR3R/SUOV2c9fq1SRGR/PjhQvNR2kNBoOhCyIWP6XUlcAsYA/wuIi8LyLXioj5KmqYKKX48YubeWdXFb+8+AROHp/R7TiafT5+tnIlzT4fP1m4kLTY2D6w1GAwGIYXPaq2VEo1AM8DTwMjgYuB9SLyzV6wbdjzp9V7ebqolJtOH8eX5+Z3O3wgGORXa9ZQ0tDAD045hYKUlD6w0mAwGIYfPWnz+5yIvACsBJzAPKXUucCJwG29Y97w5ZVNB7n31e1cMGMkt53d/SENSikeXreOdQcPckNhIbNHjuwDKw0Gg2F40hPP74vAb5VSJyilfqOUOgSglHID13QWUETOEZEdIrJbRH7Qzv7RIrJCRD4RkZUiktdmf5KIlInIsh7YP2CsL6nl1mc+Zs7oVO5bcmJEQxpe2rGDV3bv5uLJkzln/Pg+sNJgMBiGLz0Rv58CH7WuiEisiBQAKKVWdBRIROzAQ8C5wFTgMhFp+52e+4C/KqVmAHcB97TZ/3NgdQ9sHzBKa9x844m1jEiK4eGr5kQ0pOGDsjIe3bCBk/Ly+OrMmX1gpcFgMAxveiJ+zwHBkPWAta0r5gG7lVJ7lVJedHvhRW2OmQq8ZS2/HbpfROYAI4DlEdo9YNS7fSz9y0f4g4q/fHUu6QndH9Kwq7qa37z3HuPT0vjOggWIGdJgMBgM3aYnfeIdlngBoJTyikhUGOFygdKQ9TJgfptjNgJfAH6H7kSTKCLpQC1wP3AlcFZHJxCRa4FrAUaN6v7cmH2B1x/khqfWUVLj5q9fm8+4zISww64qLmZZURE7q6qo83iYnpnJj087jWgzpMFgMBgioiee32ER+VzriohcBFT13CQAbgcWisgGYCFQjvYsbwReUUqVdRZYKfWwUqpQKVWYmdn9LyL0Nkop7nhhE+/tqebeL8xgwbj0sMOuKi7mtuXLOdjYSL3HQ7PPR2lDA59UVvahxQaDwTC86YnrcD3wlNXpRNDe3NVhhCsHQvv151nbjqCUOoD2/BCRBOCLSqk6EVkAnCoiNwIJQJSIuJRSn+o0M5j4w6o9PLeujFvOGM8X5+R1HSCEZUVFxDmdVLhctPj9TM7IQERYVlRkPktkMBgMERKx+Cml9gCfscQJpZQrzKBFwAQRGYMWvUuBy0MPEJEMoEYpFQR+CDxmneOKkGOWAoWDXfgO1DXz4Bu7OHd6NreePbHb4ffV1uK026n3eBidnExyTAxBpdhXW9sH1hoMBsPxQY8ajUTkfGAaENPa8UIpdVdnYZRSfhG5GXgdsAOPKaW2iMhdwFql1EvAIuAeEVHoXp039cTOgeSht3ejUNxx/pSIOqcUpKTwXmkpsQ4HWfHxALi8Xsakpva2qQaDwXDcELH4icgfgTjgdOAR4EuEDH3oDKXUK8ArbbbdGbL8PHrmmM7ieBx4vDs29zdltW6eXVvKksJ88lLjIorj1FGjeHPvXrLi41FAo8dDk9fLzYsW9aqtBoPBcDzRkw4vJymlrgZqlVI/AxYA3a/XG8Y89PYeAG46PbJB6EGl2FZVxRljxjA+LY1Kl4us+HjuX7zYtPcZDAZDD+hJtWeL9esWkRygGj2/pwE9mP25taVcNm8UuSmRTTa9qriY8sZGfnjKKZyU3/25Pw0Gg8HQPj0Rv/+ISArwG2A9oIA/94pVw4CH3t6NTYQbTx8XUfhAMMjTmzczJiWFBXnd6yFqMBgMhs6JSPysj9iuUErVAf8UkZeBGKVUfa9aN0QprXHz/Loyrpg/ipHJkXl9K4uLOeByccepp5pZXAwGg6GXiajNzxqC8FDIuscI31F+/9YubDbhxgjb+gLBIM9s2cLYlBTm5+b2snUGg8Fg6EmHlxUi8kUxbskxFFc18c/15Vw+bxQjkmIiiuPt4mIOulxcfsIJxuszGAyGPqAn4ncdeiJrj4g0iEijiDT0kl1Dlt+/tRuHTbhxUWRtfX6rrW98airzjNdnMBgMfUJPZnhJ7E1DhgP7qpp4YUMZS08aQ1akXt++fVQ2NXHdnDnG6zMYDIY+oieD3E9rb7tSakh+Z683+P2KXUQ5bFy/aGxE4Vu9vglpaRTm5PSydQaDwWBopSdDHb4bshyD/k7fOuCMHlk0RNlz2MWLH5dzzSljyEqMzOtbsXcvh9xubpg713h9BoPB0If0pNrzwtB1EckHHuyxRUOU36/YRbTDznULI2/re2bLFialpzNnpJkrwGAwGPqSnnR4aUsZMKUX4xsy7D7k4qWNB7h6wWgyIvg6O8Abe/Zw2O02PTwNBoOhH+hJm9/v0bO6gBbRmeiZXo47/nfFLmKcdq49LbK2Pl8gwLNbtzI5PZ1Z2dm9bJ3BYDAY2tKTNr+1Ict+4B9KqTU9tGfIsauykf98coDrThtHeqRe3969VLndfGv+fOP1GQwGQz/QE/F7HmhRSgUARMQuInFKKXfvmDY0eHDFLuJ64PV5AwGe3bKFKRkZnDhiRC9bZzAYDIb26NEML0DoxJWxwJs9M2dosaOikVc2HWTpyQWkxUdFFMfyPXuobm7mCtPWZzAYDP1GT8QvRinlal2xliP7YusQ5XcrdhIf5eAbp0bu9T23dSvTMjOZYbw+g8Fg6Dd6In5NIjK7dUVE5gDNPTdpaLDtYAOvbKrgqycXkBIXmdf32u7d1DQ3mx6eBoPB0M/0pM3v28BzInIAECAbuKRXrBoC/O7NXSRGO/j6KZF7fc9v3cp04/UZDAZDv9OTQe5FIjIZmGRt2qGU8vWOWYObLQfqeW1LBbecOYHkOGdEcby6axe1LS187+STe9k6g8FgMHRFxNWeInITEK+U2qyU2gwkiMiNvWfa4OV3b+4iMcbBNaeMiSi8x+/n+W3bmJGVxfSsrF62zjAkqFwF7yyBVwv1b+WqgbbI0FPMPR1S9KTN7xvWl9wBUErVAt/ouUmDm83l9SzfWsnXTxlLcmxkXt8ru3ZR19LCFTNm9LJ1hiFB5SpYfxu0HIKYEfp3/W0msxzKmHs65OiJ+NlDP2QrInYgrJ4fInKOiOwQkd0i8oN29o8WkRUi8omIrBSRPGv7TBF5X0S2WPv6vY3xwTd3khTj4KunFEQUvsXv55/btjFzxAimZmb2rnGGocHOZWCLAneZ/nckgiNebzcMTXYuA3sMBH3gazD3dAjQkw4vrwHPiMifrPXrgFe7CmSJ5EPA2ej5QItE5CWl1NaQw+4D/qqUekJEzgDuAa4C3MDVSqldIpIDrBOR10M90L7kk7I63tx2iNvOnkhSTOReX73Hw+UnnNDL1hmGDI27wVsDQQ/4XYCC2Dxw7RtoywzdxVsP1R/B4TWgghyZ8dGZaO7pIKcn4vd94Frgemv9E3SPz66YB+xWSu0FEJGngYuAUPGbCnzHWn4beBFAKbWz9QCl1AEROQRkAv0ifg++uYuUOCdLTy6IKHyr1zcrO5sp/en1Va7SJVDXPkgYAxNvhhEL++/8vclQvxafSwue3w3JU8FbBy0VEGiBlH6uBu+NtBzq9yMSPNVQ9QFUvQd1m0ApsEeDREHsSAg0Q3M51G+CuDxoqYKYjIG22tCGiKs9lVJB4EOgGC1oZwDbwgiaC5SGrJdZ20LZCHzBWr4YSBSR9NADRGQeupp1T9sTiMi1IrJWRNYePnw4DJO65uPSOt7afohvnDqWxAi9vpd37qTB4+GK/vT6hlNbxFC/Fr8bNv0UYrMh2soMY3PBmQyeQ5A4Tmek/UFvpGVv3Y+h0FGkuRJKX4AN34X3l8KuP4K3FkYtgcLfwfy/aG8Ppe9tfAE4kvS9LboO9j2lCzh9zVBIy0FCtz0/EZkIXGb9VwHPACilTu9Fu24HlonIUmA1UA4EQmwYCTwJfMUS4WNQSj0MPAxQWFjYK7nJg2/uJDXOyVdOKogofLPPx7+2bWPOyJFMyuinUqBSsO0BvRywqthsUYDA9t8OvRL6jt8DAv4mUH5wJOjtO5cN/msJtMCmn4FrN8y6T6+3ekwpMyB+FNRvhX1/hTFXQ19PerBzGdjjtOfZuBMQnabvfwVGng02J4hT/7b+ixPsUdZ2B+x9XHuyKmBV39p0Ve4nP4HZvwF7rG4HO/JrLUtImbtVQB3xxwro7Pv7956258EmjIWq93WVpmuvPi5hLIy5CjIWQHz+0fAJY7XNoXGc+AtIngJ7n4D9T8PB13XY7DOPTYPevIbWtIzOGri0HCJEUu25HXgHuEAptRtARG7tRvhyIOSpIc/adgSl1AEsz09EEoAvtrbriUgS8F/gDqXUBxHY323Wl9SycsdhvnfOJBKiu5dkq4qLWVZUxLoDB2jx+zlv/PjuG9BZ1ZJSuv2o+SA0Hwj5tZYPrwJbO1+bcO2CNZfraprYnE//OhPDt6Ev8TdB7cdQXQSH3gZpk/42p25DK30BkiZBwnidQQ8mAl7YfDc0bIMp34OM+Xp7aPopBbv+D0qe19c45oq+talhF/gbtWhFp2tBUwHdWSNpsu64EfSBsn79bmub9+g2V7Gu7vM3HOuxukth010dn9sedVQQK1fqgpk9Vj9z0VZzQH8WaFpFwx6nO6rUbYJ3l0DieIhKh+TJMO5rWvBiO2nZGbGwfZunfhfyPgd7HoEd/wvlL8G4ayB1Zu9dg1Kw9Vf6PnlrIdCk7ynAultg6vchJlvbH5MNUakdF7Csd31a7vD+Pmsk4vcF4FLgbRF5DXgaPcNLuBQBE0RkDFr0LgUuDz1ARDKAGsur+yHwmLU9CngB3Rnm+Qhsj4gH39xFWnwUX1lQ0K1wq4qLuW35cmIcDlr8fqLsdh788EPyk5NZWBBmXJWrYN13dCZjj4WG7VbpfLHe1nxAZ66t2BzWQz4SUk6E5grwN+sMzubQmZenWseVeYoWyPqtcGjVsRmYM+GoGHrrYf+z4EzSmUFfliiV0tdUXQQ1RVC/BYIBy55cQPQLHPRqYfRU6XB7HrOu3w7xY7QQJk3SGXlM9tEXvb9FPOiHrfdA3Scw+VbIOqX940Rgwo1agPY/DWKHgkv7xqa6LeCr1Rll4gT9bIAWvuQpMOW28OJ5Z4l+FpxJurOHCoKvXmessx/QbV+BFuu3ddlaD7bo57L8VXDEaUF1l+m2MmeqfkaV6nsPGHTtSMCtn6VAMyBamBFY8PjR9OkJSZNg5q+1F7nvcdj4Y0gvhLFfO9aD7A4BD9Ru1O9JzVrdBmmLPupFBwM6vd3l+pkKfb/tUfqYI4JoLbuKtYg6E/EFGdaTlnRb/JRSLwIvikg8uqPKt4EsEfkD8IJSankX4f0icjPwOmAHHlNKbRGRu4C1SqmXgEXAPSKi0NWeN1nBvwycBqRbVaIAS5VSH3f3OsJl3f5aVu88zA/PnUx8N72+ZUVFxOPGVXuQQIuNMQl+guSyrKjo0+KnlH7hWw6C+4D+bT6gM3Vv/bHVJCoAFStg7FItcLE5EJejf6Mzjj02cYIWqqBHe0lBn85YZ95zbKYf9GmhbOs51m+DA6/q8L46cJdoEcUG674F03+kG/Vjc7VQ2jpJo46EJ+jTIlddpP+bD+rj40dD3sWQPhcSJ8Hhd/W1BFp0lacKQlSaFuHUmdCwAxp36AJCxQoo/6+Ox5moRVAFYP9zEJ3WP1VsQT9s+zVUr7WutYuWARGY+E19XcVP6fs4+su9Z49S2uvY85h+blz79DOhglYnnCZtZ7hMvFmnH+j7EXDrQsnU70HShPDiqHr/qIAGmvVyy0Httay/FXLOh6yFve/NB/36Wat442jtiCNBt9VFpep3pKWyd4SvFRFd+MmYD+Uvw/5nYO3NkHMOjL4copK7jqPlkH6eqj/SHWoCXi3UabN09XnQf6zNvgaImQUn/x1aDuvOVc0V+relUi/Xb9YFEYCadfpdt8ce/VT5MEVULzSwi0gqsAS4RCl1Zo8j7EUKCwvV2rVruz6wA257diNvbqvk/R+eQVxU98Sv8KH7GeHbzSfNKcTaFJNiXSQoFyo6nac/t1gLTKjYtfXgYkdC6b/1w9zaZmKL0dVinkNwbpjX1VNv55U5+sUMerXwtJbafXWQcdLR48SmRSUuD+JytSC2/tZ+Ahtu16VSR4KumvFUaTu8dTpem1O/wOnzdKk4pp3Zb8K9FhWEppIQQdyhq0aDHp2xOmItT9IGsSPg1OfCT49wUEHYdj8cWg3jr4W8C7sXdvtvdZXg2KUw6os9t8ffDDv/Fw69C5kLYNK3dCY60L09Q9upHAlahH2NMPoSXdBqKtFef/bZkHOufid6gqsYKt6Eyre1MESn6ZoP7BAT0gPb16Cfv95+LkLxNUDxP+DAK/rdHrUEnCmw+09H03PCDdozay0YNu3XYWNH6kJh+lxInqbfnfbS0t/UdeFOKX1scwWsvECHD3qZ9I0t9TsOqpS+S4CBpVfEbzDTU/E7/b6VTMhK4OGrC7sddsn/3Uq5G2r88OXEbZwTtwdUgCg7FI6edlTg2mtza/XgQquWWumPFzOUzmxY8LgW7+YyXb3SXG5VX7Wpjq39GFBWCb8lpNNKom4TSZsLqTOs6qY+4pVZRz0UT7X2NBwJupR7webeO49SsON3R73zSMQrGIDtD2jxHHcN5H8+cnvcZbDll/p3zFcg/wv9U50YLh0JqFK6RuDAf7WHqIKQOhtyz4e0OeF3GvG5dLV+xZu6fdjm0AWs7LMhddbRGoXuikZv4S6DPX+Bg69Cw05dKLPH6gKut063OcZkaZFLswQvNqf9e9jTwkjIuz7pspeHtfj1ZJzfsKfa5WFfVROXzI2sTv7m9C18yzWddGkk2+7inZYxlAeSuDqjHD7z6KerKNujbdVSJNVTPaUzGxzxuoqrbTWXUuA5fFQQi27SPU39Lu15xeXpruC+Bph406fP2RckjtcvdmwOxIzU9jUVaxHc+ivdy7KnnoVSsOsPWvgKLo/ca7PZYfJ3gCDseVRXw3XHe2zl8BrY/qBuH55xty5gDDY66igiAinT9b+nBg6+pntMbrpLe+s552kBcyZ+OtOfcKOurah4U4/JC/r09vHX6nOFFuRGLPx0T83+HK8Ylwcn/FgXdOzRukoStDcXlaqrZE96Sr9rXdFRWoZL6Ls+iMpHfYERv07YUKLHzs8ZnRpR+IU5yXy+roTVDYn8xz2dhOhobs4upnBEXvtVeu0x0C9mpDaI6GuMyQJm6e7e7XmPiZF9Eioi2oq4PUaXsnPP11VKVR/oDHX0pZ/u7RoOSmmhOvAqjPqSjqcn2Oww+TbdVrn7YV1Qyj0/vLDBAOx74mgv2Kk/GNoDraPTrMLEl/V9OvBf7S0VP6ULMpUrdfOAM/lob82kiboNL+ccyD5LD0foiJ6KRm/grYXkE3UvXJsD7PGA0m1z4QhfbxDyrjttRDageYhgxK8T1pXU4rAJJ+SG0RDdHhNvpmHjg8yPr+WeKb4Qj+n+7sUzGF7M3ixRDpQH256Iz7hLb/fUQPHfofw/2msbtQRyLwy/o4VSsO9JKPu37tbeW2P1bA49PELdqwdWi11n5p3hrYWtv4a6zVosx329845IQwmbQ3cayTpFt3+V/1dX6Qaa9ZCLgAcQLRa2aFjwhPaghgIJY3QBMSqkptHXqLf3J9a7vqVcwpm0ZMgyTN6IvmH9/lqm5SYT47RHFN4bV8De4EguTjkMLWXHz/RP7TEYPNhWO9o7Z3QaTLpZC9fex/X/gf/qQclZi7oWsv3PQMlzWpjGfb1329RsDj1Oa8svYedDWgBHnt3+sfXbYOu9unAx5Ttd9zAdysSPhok3wu4/6zTxNehxgtEZulNYS+XQET4YHAXE4wgjfh3gCwTZWFbHZfNGRRzHrt1vErBFM/nkn8GYqb1o3RBlMHiwXRE/Ck64U/dO3fuYHgNW9m89Hquj9rLSf+nqt+wzdVtTX3QmsTlh6g9hyy9glEBmFAAAIABJREFU5+91FWh2SMdqpXT3+b2P6tk9Zv0MEgp6347ByJG23JD2Wl9D/3tMPWWwFBCPE4z4dcD2g420+IIRt/ehFNv3bwBnBpNH9mO7lqF3SJ0Bs3+rewnu+ytsvEP3shu7VGdMrRmUPRpQkPd5mHRL3/aitEfBtDtg8891b9LaTVC1Bhr36J6zzgTdZjn51v5rIxoMDCePaSgUEIcJfTDB3PBg3f4aAGaPilD86rewrd7LyNSRJMf0Yfd9Q98hAiMWwdw/wriv6vFgay6D967SvVjFpgfUu/ZDaje63vcEe5SeWMCZDJt/qm3yVusetc2VkHHK8SV8cNRjisnSVZ0xWWY+S0OXGM+vA9aX1DEyOYaclNiIwquKt9neHM+cCaa6c8hjj9Jj47LPhjcX6XGCTft0VWNUuh7Yv/uPMLKf5newR2vPxpGkJwqwOfQYMAR2PQTZi/rHjsGE8ZgM3cSIXwes218budcX8FJR/iH1tslMzgznE4eGIYEzERA9NVjLQS1+rd3n+/ujpU0l+nuAnsNagO3RehC4+XiqwRAWptqzHSobWiiva2Z2pO19NWvZ3hCE6P9v787Do6rvxY+/P9nJIkuAyJ5gEYTAJIFAgSpwkcWKFOpKsYpWlFqg17phpWrt06e1Lddf1daqFVF/tqWlRW2lLS4gXjcCkZ2wCAkEY/Ydsn/vH+dkOoRJmITJTCbzeT1Pnsyc9ZOTk/nkfNe+vp20VnW+2CSrfi32EquhhYRYdUy+blwRm2Q17+8x0K53xD9xKBWgNPm5kZlTCkDa0A6O7JP/Hll1fegR3YehPTvYR1B1TZcut4oc6yvsWQwq/NO4oqvEoVSA0uTnRuaJUiLCQhgzsAOJq74SSnaSZZIYGd+XkK40hqK6cF2lcUVXiUOpAKV1fm7szCll3KCeRIR14H+Dgg84U9/I8fpe3OirGduVb3WVxhVdJQ6lApA++bVQ29DIvlMVHe/fV7CFIyRhQnswSpOfUkp1SZr8Wth3qoK6xiZSO9LS80welGdxMHQciGjyU0qpLkqLPVtwNnYZ1oHGLvlbQYSs+gEMucgQE+Hl2aeVUkp5hT75tZB5opQhfXrQP66do7IYA/lbMD3HklV+hsv0qU8ppbosTX4ujDHszCllfEeKPCsPw5k8TsVOoaquTos8lVKqC9Pk5+JU2RkKKms71rk9/z0IjeBgk9XJWDu3K6VU16XJz8VOZ+f2dia/pgYo+ADiJ5FVWklsRASD4jowE7hSSimf0OTn4rMTZURHhDLq4nYmrpKdVuf2hBkcLCpiVHw8op3blVKqy9Lk52JnTimOwb0IC23nZcnfAhE9qY4Zw8mKCq3vU0qpLs4vyU9E5orIIRE5KiKr3KwfJiLvisgeEdkqIoNd1t0qIkfsr1u9FdPpugYO5FW0v4tDQzUUb4f+V5BVUgZofZ9SSnV1Pk9+IhIK/Aa4ChgNLBKRlpPe/Qp4xRgzDngc+Jm9bx/gUWASMBF4VEQ6OBTL2fbkltPYZNo/skvhh9BUD/1nkFVUhACXxsd7IySllFKdxB9PfhOBo8aYY8aYOuBPwDdabDMaeM9+vcVl/RzgbWNMiTGmFHgbmOuNoDJPWI1dUoe0M/nlb4HoQRD3FbKKikjq1YuoMB07QCmlujJ/JL9BwEmX97n2Mle7gW/arxcCcSIS7+G+iMidIrJDRHYUFhZ6FFRmTinD+8XQO6Ydo7LUFEDZPkiYQRNwqLhY6/uUUioAdNUGL/cB00TkM2AacApo9HRnY8zzxpgJxpgJ/TyofzPGkHmirP1dHAret773n86J8nLONDRo8lNKqQDgj+R3Chji8n6wvczJGPOFMeabxphU4GF7WZkn+3ZEdvFpSqrr2lffZw9nRs/R0COBrKIiAE1+SikVAPyR/DKAESKSJCIRwE3Am64biEhfEWmO7SFgrf3638BsEeltN3SZbS+7IJkd6dxe9TlUn4SEGQAcLCykZ2QkF8fGXmg4SimlOpnPk58xpgFYjpW0DgJ/NsbsF5HHRWS+vdl04JCIHAYSgJ/a+5YAP8FKoBnA4/ayC7LzRClxkWGM6N+OxJW/FULCoN/XAMgqKmJU377auV0ppQKAX5olGmM2AZtaLHvE5fUGYEMr+67lP0+CXpGZU0rK0F6EhHiYuJoarfq++IkQHkt5TQ1fVFUx+5JLvBmWUkqpTtJVG7z4TGVNPYfyK9tX31e2C+rKnEWeh4qLAa3vU0qpQBH0yW/3yXKMoX3JL38LhMdCn/GAVd8XKsII7dyulFIBIeiT386cUkQgZYiHw5o1nIGij6Hf5RASDlj1fcN79yYiNLQTI1VKKeUtQZ/8Mk+UMjIhjriocM92KPoYGuucRZ4NTU0cLinRmduVUiqABHXya2oyZJ4oJbU9XRzyt0CPi+GiUQBkl5VR19iog1krpVQACerk93lhFZU1DZ7X99WWQNlu6D8d7C4NB+3h07Sxi1JKBY6gTn7/mbndw/q+gvetkV3sIk+w6vv6RkfTNzq6M0JUSinVCYI6+WWeKKV3dDhJfWM82yH/PbhoJEQPdC7KsmduV0opFTiCOvntzCklbWhvz0Zlqcq2vhKmOxeVnDlDwenTWuSplFIBJmiTX9npOj4vrCbN0/q+/C0QEgr9r3Au0sGslVIqMAVt8vvsRBng4WDWpsmq7+s9HsIvci7OKioiPCSES/r06awwlVJKdYKgTX6ZJ0oJDREcQ3qef+OyvVBbfFZDF7Baen6lTx/CQoL2MiqlVEDyy8DWXcHOnFIuGxBHdEQblyD/fTj8DBR9Yr1vrHGuqm9s5GhpKfMvvbSTI1VKKeVtQfnI0tDYxO6TZYxvq8gz/33IvBfOfAmmAUIiYdcqaznweWkpDU1NWt+nlFIBKCif/A7lV1Jd19h2Y5fDz0BYDDTVW3V+0YP+szxhmnZuVwGtvr6e3Nxcampqzr+x6taioqIYPHgw4eEeDvHYTQRl8sv0pLFL1XGISoDqHAiJgLA4wFjLsRq7JMTE0LtHDx9ErJR35ebmEhcXR2Jiok7AHMSMMRQXF5Obm0tSUpK/w/GpoCz2zMwppV9cJIN7t5G4YpOgoQpiEqHnaGs4s4YqiE3CGENWcbEOZq0CVk1NDfHx8Zr4gpyIEB8fH5QlAMGZ/E6UMv58ndsvXQ4N1dBQCRIG9RXW+0uXU3j6NCVnzmiRpwpomvgUBO99EHTJr6iqlpzi06QNO894ngnTIG0NRPWHmnzre9oaSJjm7NyuMzkopVRgCro6v0x7MGuPZnJImGZ9tZBVVERUWBjDenrQR1ApdY7i4mJmzpwJwJdffkloaCj97H8mt2/fTkRERJv7b926lYiICKZMmdLpsXrTF198wcqVK9mwYYO/Qwl6QZf8dp4oJTxUGDOw44nrYGEhl/bpQ6h2blfBornPa9Vxqz780uVu/zH0VHx8PLt27QLgscceIzY2lvvuu8/j/bdu3UpsbKzfk19jYyOhoaEebz9w4EBNfF1E0H16Z+aUkjyoJ1Hhnt+wrmoaGjhWVqb1fSp4NPd5rSmwWkDXFFjv7T6v3rJz506mTZvG+PHjmTNnDnl5eQA89dRTjB49mnHjxnHTTTeRnZ3N7373O5588klSUlL44IMPzjrO9u3bmTx5MqmpqUyZMoVDhw4BVqK67777SE5OZty4cTz99NMAZGRkMGXKFBwOBxMnTqSyspJ169axfPly5zHnzZvH1q1bAYiNjeXee+/F4XDw8ccf8/jjj5Oenk5ycjJ33nknxhgAjh49ypVXXonD4SAtLY3PP/+c7OxskpOTnfHcf//9pKenM27cOJ577jkA8vLyuOKKK0hJSSE5Ofmcn095R1A9+dU1NLEnt5ybvzqsw8c4WlJCkzGa/FTwaO7z2jyubfN3u8+rNxhjWLFiBW+88Qb9+vVj/fr1PPzww6xdu5af//znHD9+nMjISMrKyujVqxfLli1r9Wlx1KhRfPDBB4SFhfHOO+/wwx/+kL/+9a88//zzZGdns2vXLsLCwigpKaGuro4bb7yR9evXk56eTkVFBT3O032purqaSZMmsWbNGgBGjx7NI488AsC3v/1t/vGPf3DNNdewePFiVq1axcKFC6mpqaGpqYmCggLncV588UV69uxJRkYGtbW1TJ06ldmzZ/O3v/2NOXPm8PDDD9PY2Mjp06e9co3V2fyS/ERkLvBrIBT4vTHm5y3WDwVeBnrZ26wyxmwSkXDg90AaVuyvGGN+5ul5D+RVUNvQ5PnM7W7oTA4q6DT3eXUVFuvs8+oNtbW17Nu3j1mzZgHWU9GAAQMAGDduHIsXL2bBggUsWLDgvMcqLy/n1ltv5ciRI4gI9fX1ALzzzjssW7aMsDDrY69Pnz7s3buXAQMGkJ6eDsBFF13U6nGbhYaGcu211zrfb9myhV/84hecPn2akpISxowZw/Tp0zl16hQLFy4ErI7kLW3evJk9e/Y4i0HLy8s5cuQI6enp3H777dTX17NgwQJSUlLOG5NqP58nPxEJBX4DzAJygQwRedMYc8Bls9XAn40xz4rIaGATkAhcD0QaY8aKSDRwQET+aIzJ9uTcmc6Z2zue/A4WFjIoLo64yMgOH0OpgBKbZBV1usxo0tzn1VuMMYwZM4aPP/74nHVvvfUW27Zt4+9//zs//elP2bt3b5vH+tGPfsSMGTPYuHEj2dnZTJ8+vd3xhIWF0dTU5Hzv2g8uKirKWc9XU1PD3XffzY4dOxgyZAiPPfaYx33mjDE8/fTTzJkz55x127Zt46233mLJkiX84Ac/4JZbbmn3z6Da5o86v4nAUWPMMWNMHfAn4BsttjFA819aT+ALl+UxIhIG9ADqgApPT7zzRCmDevXg4p7n/hfmiebO7frUp4JKc5/X+gprqD+XPq/eEhkZSWFhoTP51dfXs3//fpqamjh58iQzZszgiSeeoLy8nKqqKuLi4qisrHR7rPLycgYNsoYjXLdunXP5rFmzeO6552hoaACgpKSEkSNHkpeXR0ZGBgCVlZU0NDSQmJjIrl27nOffvn2723M1J7q+fftSVVXlfIqLi4tj8ODBvP7664D1ZNuy+HLOnDk8++yzzifTw4cPU11dTU5ODgkJCSxdupQ77riDzMzMdl9PdX7+SH6DgJMu73PtZa4eA24WkVysp74V9vINQDWQB5wAfmWMKWl5AhG5U0R2iMiOQnsMToDPckpJHXqe/n1tyKuqoqK2Vkd2UcGljT6v3hISEsKGDRt48MEHcTgcpKSk8NFHH9HY2MjNN9/M2LFjSU1NZeXKlfTq1YtrrrmGjRs3um3w8sADD/DQQw+RmprqTHQAd9xxB0OHDmXcuHE4HA7+8Ic/EBERwfr161mxYgUOh4NZs2ZRU1PD1KlTSUpKYvTo0axcuZK0tDS3cffq1YulS5eSnJzMnDlznMWnAK+++ipPPfUU48aNY8qUKXz55Zdn7XvHHXcwevRo0tLSSE5O5q677qKhoYGtW7ficDhITU1l/fr1fP/73/fadVb/Ic0tk3x2QpHrgLnGmDvs998GJhljlrts8wM7tjUiMhl4EUgGJgN3A0uA3sAHwFXGmGOtnW/ChAlmx44d5JWfYfLP3uPRa0Zz29SOFde8d/w4T37yCc9cdRXDenU8iSrlbwcPHuSyyy7zdxiqi3B3P4jITmPMBD+F1On88eR3Chji8n6wvczVd4A/AxhjPgaigL7At4B/GWPqjTEFwIeAR7+czJx2zNzeioOFhUSHhzNUO7crpVRA80fyywBGiEiSiEQANwFvttjmBDATQEQuw0p+hfby/7KXxwBfBbI8OenOnFKiwkMYPfD8rblak1VUxCgdDFgppQKez5OfMaYBWA78GziI1apzv4g8LiLz7c3uBZaKyG7gj8ASY5XP/gaIFZH9WEn0JWPMHk/Om3milHGDehEe2rEf+XR9PTnl5drYRSmlugG/9PMzxmzCasjiuuwRl9cHgKlu9qvC6u7QLjX1jez/opzvfG14B6K1HC4uxqCDWSulVHcQFMOb7TtVTn2jIe0CWnpmFRUhwKXx8d4LTCmllF8ERfLb2dy5/QJHdhnWsyfR4eHeCksppZSfBEXyyzxRyrD4aPrGdmxUFmOM1dhF6/uU8ori4mJSUlJISUnh4osvZtCgQc73dXV1be67Y8cOVq5ced5z+HvGB18Jlp/T24JiYOudOWVcMaLjiSu3ooLq+npNfipovZ+dzTMZGRwvLSWpd2+Wp6czLTGxw8c735RGDQ0NzjE4W5owYQITJpy/h9NHH33U4fj8pb1TJEFg/pxdQbd/8qtraKKoqpbUCyjyPKiDWasg9n52Nvdu3kxBdTUJsbEUVFdz7+bNvJ+d7dXzLFmyhGXLljFp0iQeeOCBVqcm2rp1K/PmzQOsxHn77bczffp0hg8fzlNPPeU8XmxsrHP76dOnc9111zFq1CgWL17snHZo06ZNjBo1ivHjx7Ny5UrncV1lZ2dz+eWXk5aWRlpa2lnJ5oknnmDs2LE4HA5WrVoFuJ/KyDVmgOXLlzuHXktMTOTBBx8kLS2Nv/zlL7zwwgukp6fjcDi49tprncOi5efns3DhQhwOBw6HwxlH888J8Mtf/tI5RdKjjz4KWLNQXH311TgcDpKTk1m/fv0F/Ja6j27/5He6rhGA8RfQuT2rqIi4iAgGxsV5KyylAsYzGRnERERwkT2Ye/P3ZzIyLujpz53c3Fw++ugjQkNDqaiocDs1UUtZWVls2bKFyspKRo4cyXe/+13CW9TNf/bZZ+zfv5+BAwcydepUPvzwQyZMmMBdd93Ftm3bSEpKYtGiRW5j6t+/P2+//TZRUVEcOXKERYsWsWPHDv75z3/yxhtv8OmnnxIdHU1JiTXSorupjE6ePOn22M3i4+OdY3gWFxezdOlSAFavXs2LL77IihUrWLlyJdOmTWPjxo00NjZSVVV11jE2b97MkSNH2L59O8YY5s+fz7Zt2ygsLGTgwIG89dZbgDX2qQqK5NdA74hQRl7c8cR1sLCQUX37aud2FZSOl5aS4PJ0ARAbEcHx0lKvn+v66693Fvu1NjVRS1dffTWRkZFERkbSv39/8vPzGTx48FnbTJw40bksJSWF7OxsYmNjGT58OElJ1nCHixYt4vnnnz/n+PX19Sxfvpxdu3YRGhrK4cOHAWuKpNtuu43o6GjAmiKpsrLyvFMZuXPjjTc6X+/bt4/Vq1dTVlZGVVWVc9aH9957j1deeQWwplXq2WKkqc2bN7N582ZSU1MBqKqq4siRI1x++eXce++9PPjgg8ybN4/LL7/co5i6u26f/KrrGpkxtBehIe1PXO9nZ/PkJ5+wNTuby/r1Y9qwYV7/T1epri6pd28KqqudT3wAVXV1JPXueGlKa2JiYpyvPZ2aKNIlrtDQ0LMGs27PNq158sknSUhIYPfu3TQ1NXmc0Fy1NUUSnP1zL1myhNdffx2Hw8G6deucM8ifjzGGhx56iLvuuuucdZmZmWzatInVq1czc+ZM5+S7wazb1/nV1Dd2aDzP5nqOE+XlRIaFUd/Y2Cn1HEp1dcvT06muq6OitpYmY6ioraW6ro7lLjMYdIbWpibylpEjR3Ls2DGy7b/p1urCysvLGTBgACEhIbz66qs0NlpVKbNmzeKll15y1smVlJS0OpXRsGHDOHDgALW1tZSVlfHuu++2GldlZSUDBgygvr6e1157zbl85syZPPvss4DVMKZl8eWcOXNYu3atszj01KlTFBQU8MUXXxAdHc3NN9/M/fffr1Mk2bp98oOO9e9rrucwgAD9Y2KIiYjgGXveL6WCxbTERNbMnk3/mBjyq6roHxPDmtmzO70UpLWpibylR48e/Pa3v2Xu3LmMHz+euLi4c4oSAe6++25efvllHA4HWVlZzqe0uXPnMn/+fCZMmEBKSgq/+tWvAPdTGQ0ZMoQbbriB5ORkbrjhBmfRpDs/+clPmDRpElOnTmXUqFHO5b/+9a/ZsmULY8eOZfz48Rw4cOCs/WbPns23vvUtJk+ezNixY7nuuuuorKxk7969TJw4kZSUFH784x+zevVqb1y+gOfzKY18rW/SZebo/t30io5o134Tnn+ehNhYik+fdhbxNBlDflUVO+68s5OiVco3dEojS1VVFbGxsRhj+N73vseIESO45557/B2Wz+mURt1QYnxMuxMfWPUcVXV19IuJcdZtdFY9h1LKP1544QVSUlIYM2YM5eXlbuvLVPfU7ZNfR/mrnkMp5Tv33HMPu3bt4sCBA7z22mvOlpuq+9Pk1wp/1XMo5SvdvcpDeSZY74Nu39XhQkxLTNRkp7qlqKgoiouLidfJmYOaMYbi4uIOdd8IdJr8lApCgwcPJjc3l8LCQn+HovwsKirqnEEBgoEmP6WCUHh4uHNkE6WCkdb5KaWUCjqa/JRSSgUdTX5KKaWCTrcf4UVEKoFD/o7DA32BIn8H4QGN07s0Tu8KhDgDIUaAkcaYbjuPWzA0eDkUCEP0iMgOjdN7NE7v0ji9JxBiBCtOf8fQmbTYUymlVNDR5KeUUiroBEPyO3dq5q5J4/QujdO7NE7vCYQYIXDi7JBu3+BFKaWUaikYnvyUUkqps2jyU0opFXS6TfITkbkickhEjorIKjfrI0Vkvb3+UxFJ9EOMQ0Rki4gcEJH9IvJ9N9tMF5FyEdllfz3i6zjtOLJFZK8dwzlNnsXylH0994hImh9iHOlynXaJSIWI/HeLbfxyPUVkrYgUiMg+l2V9RORtETlif3c7M7KI3Gpvc0REbvVDnL8UkSz797pRRHq1sm+b94gP4nxMRE65/G6/3sq+bX42dHKM613iyxaRXa3s68tr6fZzqCven53KGBPwX0Ao8DkwHIgAdgOjW2xzN/A7+/VNwHo/xDkASLNfxwGH3cQ5HfhHF7im2UDfNtZ/HfgnIMBXgU+7wD3wJTCsK1xP4AogDdjnsuwXwCr79SrgCTf79QGO2d972697+zjO2UCY/foJd3F6co/4IM7HgPs8uC/a/GzozBhbrF8DPNIFrqXbz6GueH925ld3efKbCBw1xhwzxtQBfwK+0WKbbwAv2683ADPFxxOZGWPyjDGZ9utK4CAwyJcxeNE3gFeM5ROgl4gM8GM8M4HPjTE5fozByRizDShpsdj1HnwZWOBm1znA28aYEmNMKfA2MNeXcRpjNhtjGuy3nwB+n++mlevpCU8+G7yirRjtz5obgD92xrnbo43PoS53f3am7pL8BgEnXd7ncm5ScW5j/2GXA/E+ic4Nu9g1FfjUzerJIrJbRP4pImN8Gth/GGCziOwUkTvdrPfkmvvSTbT+wdIVridAgjEmz379JZDgZpuudl1vx3rCd+d894gvLLeLZ9e2UkzXVa7n5UC+MeZIK+v9ci1bfA4F4v3ZYd0l+QUUEYkF/gr8tzGmosXqTKyiOwfwNPC6r+Ozfc0YkwZcBXxPRK7wUxznJSIRwHzgL25Wd5XreRZjlSF16X5GIvIw0AC81som/r5HngUuAVKAPKxixa5qEW0/9fn8Wrb1ORQI9+eF6i7J7xQwxOX9YHuZ221EJAzoCRT7JDoXIhKOdcO9Zoz5W8v1xpgKY0yV/XoTEC4ifX0cJsaYU/b3AmAjVvGRK0+uua9cBWQaY/Jbrugq19OW31w0bH8vcLNNl7iuIrIEmAcstj8Iz+HBPdKpjDH5xphGY0wT8EIr5/f79bQ/b74JrG9tG19fy1Y+hwLm/vSG7pL8MoARIpJkPwXcBLzZYps3geaWSdcB77X2R91Z7HL/F4GDxpj/aWWbi5vrIkVkItbvyKdJWkRiRCSu+TVWA4h9LTZ7E7hFLF8Fyl2KTHyt1f+qu8L1dOF6D94KvOFmm38Ds0Wkt12MN9te5jMiMhd4AJhvjDndyjae3COdqkUd88JWzu/JZ0NnuxLIMsbkulvp62vZxudQQNyfXuPvFjfe+sJqfXgYq2XXw/ayx7H+gAGisIrFjgLbgeF+iPFrWEUJe4Bd9tfXgWXAMnub5cB+rFZpnwBT/BDncPv8u+1Ymq+na5wC/Ma+3nuBCX76vcdgJbOeLsv8fj2xknEeUI9VL/IdrDrmd4EjwDtAH3vbCcDvXfa93b5PjwK3+SHOo1j1Os33aHMr6YHAprbuER/H+ap97+3B+uAe0DJO+/05nw2+itFevq75fnTZ1p/XsrXPoS53f3bmlw5vppRSKuh0l2JPpZRSymOa/JRSSgUdTX5KKaWCjiY/pZRSQUeTn1JKqaCjyU91GyJiRGSNy/v7ROQxLx17nYhc541jnec814vIQRHZ0tnnanHeJSLyjC/PqZQ/afJT3Ukt8E0/juDilj3Ch6e+Ayw1xszorHiUUpr8VPfSADwP3NNyRcsnNxGpsr9PF5H3ReQNETkmIj8XkcUist2eX+0Sl8NcKSI7ROSwiMyz9w8Va/67DHuA5btcjvuBiLwJHHATzyL7+PtE5Al72SNYHZBfFJFfutnnfpfz/NhelijW3Huv2U+MG0Qk2l43U0Q+s8+zVkQi7eXpIvKRPdj39ubRRYCBIvIvseZp+4XLz7fOjnOviJxzbZUKRO35j1SpQPAbYE/zh7eHHMBlWNPRHMMazWKiWJN8rgCaJ8hNxBpz8RJgi4h8BbgFa2i3dDu5fCgim+3t04BkY8xx15OJyECsefLGA6VYo/kvMMY8LiL/hTVH3Y4W+8wGRtjnF+BNsQY/PgGMxBpN5EMRWQvcbRdhrgNmGmMOi8grwHdF5LdYY0zeaIzJEJGLgDP2aVKwRvivBQ6JyNNAf2CQMSbZjsPtxLZKBRp98lPdirFGp38FWNmO3TKMNcdZLdYQWM3Jay9Wwmv2Z2NMk7GmpTkGjMIa2/AWsWbo/hRriKgR9vbbWyY+Wzqw1RhTaKzptV7Dmgi1LbPtr8+wZqoY5XKek8aYD+3X/x/r6XEkcNwYc9jj9Og8AAAB00lEQVRe/rJ9jpFAnjEmA5wDfzfP3feuMabcGFOD9bQ6zP45h4vI0/aYny1nIVEqIOmTn+qO/h9WgnjJZVkD9j97IhKCNat3s1qX100u75s4+2+k5ViABuspbIUx5qzBfUVkOlDdsfDdEuBnxpjnWpwnsZW4OsL1OjRizeZeKiIOrElMl2FNyHp7B4+vVJehT36q2zHGlAB/xmo80iwbq5gRrLn/wjtw6OtFJMSuBxwOHMIa0f67Yk0Rg4hcao/M35btwDQR6SsioVizUrx/nn3+Ddwu1hxsiMggEelvrxsqIpPt198C/teOLdEumgX4tn2OQ8AAEUm3jxPXVoMcu/FQiDHmr8BqrKJcpQKePvmp7moN1owOzV4A3hCR3cC/6NhT2QmsxHUR1ij9NSLye6yi0Ux7qphCYEFbBzHG5InIKmAL1hPdW8YYd9PHuO6zWUQuAz62TkMVcDPWE9ohrAlQ12IVVz5rx3Yb8Bc7uWVgzc5QJyI3Ak+LSA+s+r4r2zj1IOAl+2kZ4KG24lQqUOisDkoFMLvY8x/NDVKUUp7RYk+llFJBR5/8lFJKBR198lNKKRV0NPkppZQKOpr8lFJKBR1NfkoppYKOJj+llFJB5/8AuRFYckstrLEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run CNN model, gather training/test accuracies for each epoch\n",
        "model = buildCNN()\n",
        "history = model.fit(trainX, trainY, epochs = 20, \n",
        "                    validation_data=(testX, testY))\n",
        "\n",
        "epochsCNN = list(range(1,21))\n",
        "plt.plot(history.history['accuracy'])\n",
        "# Plot test/validation accuracies\n",
        "plt.plot()\n",
        "plt.scatter(epochsCNN, history.history['val_accuracy'],label='Test accuracies',c='orange',alpha=0.7)\n",
        "plt.plot(epochsCNN, history.history['val_accuracy'],'orange',alpha=0.7)\n",
        "plt.scatter(epochsCNN, history.history['accuracy'],label='Training accuracies',c='teal',alpha=0.7)\n",
        "plt.plot(epochsCNN, history.history['accuracy'],'teal',alpha=0.7)\n",
        "plt.title('Training and test accuracies with respect to number of epochs for CNNs')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlim(0, max(epochsCNN))\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MP3.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}